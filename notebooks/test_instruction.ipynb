{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93dcfdc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 1.26.4\n",
      "matplotlib version: 3.9.2\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.6.0+cu118\n",
      "tqdm version: 4.66.5\n",
      "tensorflow version: 2.19.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"numpy\",       # PyTorch & TensorFlow dependency\n",
    "    \"matplotlib\",  # Plotting library\n",
    "    \"tiktoken\",    # Tokenizer\n",
    "    \"torch\",       # Deep learning library\n",
    "    \"tqdm\",        # Progress bar\n",
    "    \"tensorflow\",  # For OpenAI's pretrained weights\n",
    "]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "365c0537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\MSI\\OneDrive\\Dokumen\\datmin\\LLM\\GPT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:9: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<>:9: SyntaxWarning: invalid escape sequence '\\i'\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_16884\\659354045.py:9: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  file_path = \"data\\instruction\\instruction-data.json\"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "os.chdir(\"C:/Users/MSI/OneDrive/Dokumen/datmin/LLM/GPT\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "\n",
    "file_path = \"data\\instruction\\instruction-data.json\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a24f482f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6ffef91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ed9146e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another example entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Another example entry:\\n\", data[999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61763423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "819b6d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58f83d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7a4836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_portion = int(len(data) * 0.85)  # 85% for training\n",
    "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
    "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4e92914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "201c0d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1f29a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c0c95a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    # and increase the max length by +1, which will add one extra\n",
    "    # padding token below\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst = []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to batch_max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        # Via padded[:-1], we remove the extra padded token\n",
    "        # that has been added via the +1 setting in batch_max_length\n",
    "        # (the extra padding token will be relevant in later codes)\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_lst.append(inputs)\n",
    "\n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e52eefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6638b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_2(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "583bf308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68ad5d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs and targets\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "\n",
    "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        # New: Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs and targets to tensors and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "254649c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e1e550a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0],  # 1st training example\n",
    "     [-0.5, 1.5]]  # 2nd training example\n",
    ")\n",
    "targets_1 = torch.tensor([0, 1])\n",
    "\n",
    "\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c45e57c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]  # New 3rd training example\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ea0eb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21c1c3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e31815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "212cbb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5873fb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "173643d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61505738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
      "          985,   576,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
      "         5156,   318,   845, 13779,    13,   198,   198, 21017, 18261,    25,\n",
      "          198,   464,  5156,   318,   355, 13779,   355,   257,  4936,    13,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ee4e32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "         2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "        46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,   985,\n",
      "          576,    13,   198,   198, 21017, 23412,    25,   198,   464,  5156,\n",
      "          318,   845, 13779,    13,   198,   198, 21017, 18261,    25,   198,\n",
      "          464,  5156,   318,   355, 13779,   355,   257,  4936,    13, 50256,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a93f7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:29: SyntaxWarning: invalid escape sequence '\\g'\n",
      "<>:29: SyntaxWarning: invalid escape sequence '\\g'\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_16884\\470881280.py:29: SyntaxWarning: invalid escape sequence '\\g'\n",
      "  models_dir=\"models\\gpt2\"\n",
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 76.5kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 764kiB/s] \n",
      "hparams.json: 100%|██████████| 91.0/91.0 [00:00<00:00, 90.6kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 1.42G/1.42G [31:54<00:00, 741kiB/s]   \n",
      "model.ckpt.index: 100%|██████████| 10.4k/10.4k [00:00<00:00, 10.3MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 927k/927k [00:01<00:00, 602kiB/s]  \n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:01<00:00, 407kiB/s]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.abspath(\"src\"))\n",
    "\n",
    "\n",
    "from utils.gpt_download import download_and_load_gpt2\n",
    "from gpt import GPTModel, load_weights_into_gpt\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"models\\gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38ccea47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71dc98f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.train import calc_loss_loader, train_model_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab479b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.825909423828125\n",
      "Validation loss: 3.761933755874634\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f62dbc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.626\n",
      "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.102\n",
      "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.944\n",
      "Ep 1 (Step 000015): Train loss 0.857, Val loss 0.906\n",
      "Ep 1 (Step 000020): Train loss 0.776, Val loss 0.881\n",
      "Ep 1 (Step 000025): Train loss 0.754, Val loss 0.859\n",
      "Ep 1 (Step 000030): Train loss 0.799, Val loss 0.836\n",
      "Ep 1 (Step 000035): Train loss 0.714, Val loss 0.808\n",
      "Ep 1 (Step 000040): Train loss 0.672, Val loss 0.806\n",
      "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.789\n",
      "Ep 1 (Step 000050): Train loss 0.663, Val loss 0.783\n",
      "Ep 1 (Step 000055): Train loss 0.760, Val loss 0.763\n",
      "Ep 1 (Step 000060): Train loss 0.719, Val loss 0.743\n",
      "Ep 1 (Step 000065): Train loss 0.653, Val loss 0.735\n",
      "Ep 1 (Step 000070): Train loss 0.532, Val loss 0.729\n",
      "Ep 1 (Step 000075): Train loss 0.569, Val loss 0.728\n",
      "Ep 1 (Step 000080): Train loss 0.605, Val loss 0.725\n",
      "Ep 1 (Step 000085): Train loss 0.509, Val loss 0.709\n",
      "Ep 1 (Step 000090): Train loss 0.562, Val loss 0.691\n",
      "Ep 1 (Step 000095): Train loss 0.500, Val loss 0.682\n",
      "Ep 1 (Step 000100): Train loss 0.503, Val loss 0.677\n",
      "Ep 1 (Step 000105): Train loss 0.564, Val loss 0.670\n",
      "Ep 1 (Step 000110): Train loss 0.554, Val loss 0.666\n",
      "Ep 1 (Step 000115): Train loss 0.508, Val loss 0.663\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
      "Ep 2 (Step 000120): Train loss 0.435, Val loss 0.672\n",
      "Ep 2 (Step 000125): Train loss 0.451, Val loss 0.686\n",
      "Ep 2 (Step 000130): Train loss 0.447, Val loss 0.682\n",
      "Ep 2 (Step 000135): Train loss 0.405, Val loss 0.681\n",
      "Ep 2 (Step 000140): Train loss 0.409, Val loss 0.681\n",
      "Ep 2 (Step 000145): Train loss 0.368, Val loss 0.681\n",
      "Ep 2 (Step 000150): Train loss 0.382, Val loss 0.675\n",
      "Ep 2 (Step 000155): Train loss 0.414, Val loss 0.675\n",
      "Ep 2 (Step 000160): Train loss 0.415, Val loss 0.683\n",
      "Ep 2 (Step 000165): Train loss 0.379, Val loss 0.685\n",
      "Ep 2 (Step 000170): Train loss 0.323, Val loss 0.681\n",
      "Ep 2 (Step 000175): Train loss 0.337, Val loss 0.669\n",
      "Ep 2 (Step 000180): Train loss 0.392, Val loss 0.656\n",
      "Ep 2 (Step 000185): Train loss 0.415, Val loss 0.657\n",
      "Ep 2 (Step 000190): Train loss 0.341, Val loss 0.648\n",
      "Ep 2 (Step 000195): Train loss 0.329, Val loss 0.634\n",
      "Ep 2 (Step 000200): Train loss 0.310, Val loss 0.635\n",
      "Ep 2 (Step 000205): Train loss 0.352, Val loss 0.631\n",
      "Ep 2 (Step 000210): Train loss 0.367, Val loss 0.630\n",
      "Ep 2 (Step 000215): Train loss 0.395, Val loss 0.634\n",
      "Ep 2 (Step 000220): Train loss 0.302, Val loss 0.648\n",
      "Ep 2 (Step 000225): Train loss 0.347, Val loss 0.661\n",
      "Ep 2 (Step 000230): Train loss 0.294, Val loss 0.656\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
      "Training completed in 40.35 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b80b2b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHWCAYAAAD6oMSKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB6/klEQVR4nO3dd3hT1R8G8Ddp0nS3tKUL6GK0bEpZZSMbBBGVISC4EGWIyE/FiThwoThRVEBRpgxRkClTNhQotJRVaIGWMruTNMn5/XHblFAoHRlt+n6eJ0+Tm3NvvveWwMu595wrE0IIEBEREVGVJ7d1AURERERkHgx2RERERHaCwY6IiIjITjDYEREREdkJBjsiIiIiO8FgR0RERGQnGOyIiIiI7ASDHREREZGdYLAjIiIishMMdkRULchkMqxevdrWZRARWRSDHRFVCTKZrMTHmDFjbF0iEZHNKWxdABFRaaSmphqfL126FG+//TYSExONy5ydnW1RFhFRpcIeOyKqEgICAowPT09PyGQyk2WLFi1C3bp14ejoiIiICCxcuLDE7c2YMQP+/v44cuQIAGD37t3o3LkznJ2dUadOHUyaNAk5OTnG9qGhofjwww/x1FNPwd3dHcHBwZg7d67xfa1WiwkTJiAwMBBOTk4IDQ3FzJkz7/n527ZtQ5s2beDq6govLy906NABFy5cML7/119/ITo6Gk5OTggPD8e7774LnU5nfD8jIwNjx46Fn58fPDw88MADD+Do0aPG96dPn44WLVpg4cKFCA0NhaenJ4YNG4asrKxSH3MiqnoY7Iioylu1ahVefPFFvPzyyzh+/Diee+45PPnkk9i6dWuxtkIIvPjii/j555+xa9cutGjRAnFxcejduzcGDx6MY8eOYenSpdi1axcmTJhgsu6sWbPQqlUrxMbG4oUXXsDzzz+PkydPAgC++uorrFmzBsuWLUNiYiJ+++03hIaG3rVenU6HQYMGoUuXLjh27Bj27NmDsWPHQiaTAQA2bNiAkSNHYtKkSYiPj8cPP/yABQsW4IMPPjDuQ//+/ZGWloZ169bh0KFDaNmyJbp3744bN24YP+fs2bNYvXo1/v77b/z999/Yvn07PvroI3McciKqrAQRURUzf/584enpaXzdvn178eyzz5q0eeyxx0S/fv2MrwGI5cuXi5EjR4rIyEiRkpJifG/UqFFi7NixJuvv3LlTyOVykZeXJ4QQIiQkRIwcOdL4vsFgEH5+fmLOnDlCCCEmTpwoHnjgAWEwGO5b//Xr1wUAsW3btru+36lTJ/Hhhx+aLFu4cKEIDAwUQgixZcsW4eHhIdRqtUmbunXrih9++EEIIcQ777wjXFxcRGZmpvH9//3vf6Jt27b3rY+Iqi5eY0dEVV5CQgLGjh1rsqxDhw748ssvTZa99NJLUKlU2Lt3L3x9fY3LDx06hDNnzuD33383LhNCwGAwICkpCQ0bNgQANGvWzPh+4ang9PR0AMCYMWPQs2dPREREoE+fPnjwwQfRq1evu9br7e2NMWPGoHfv3ujZsyd69OiBIUOGIDAw0FjPgQMHjD10AKDX66FWq5Gbm4tDhw4hOzsbPj4+JtvNy8vD2bNnja9DQ0Ph7u5ufB0YGGisl4jsE4MdEdmFwtOYhYQQxZb17NkTixcvxoYNGzBixAjjcoPBgOeeew6TJk0qtt3g4GDjc6VSWewzDQYDAKBly5ZISkrCP//8g82bN2PIkCHo0aMH/vjjj7vWO3/+fEyaNAnr16/H0qVL8eabb2LTpk1o164dDAYD3n33XQwePLjYek5OTjAYDAgMDMS2bduKve/l5VWqeonIPjHYEVGV17BhQ+zatQtPPPGEcdnu3buNPW2FBg4ciAEDBuDxxx+Hg4MDhg0bBkAKZSdOnEC9evUqVIeHhweGDh2KoUOH4tFHH0WfPn1w48YNeHt737V9VFQUoqKiMG3aNMTExGDRokVo164dWrZsicTExHvW07JlS6SlpUGhUNzzOj4iqp4Y7Iioyvvf//6HIUOGGAcQ/PXXX1i5ciU2b95crO3DDz+MhQsXYtSoUVAoFHj00Ufx6quvol27dhg/fjyeffZZuLq6IiEhAZs2bcLXX39dqhq++OILBAYGokWLFpDL5Vi+fDkCAgJMetAKJSUlYe7cuRg4cCCCgoKQmJiIU6dOGYPp22+/jQcffBB16tTBY489BrlcjmPHjiEuLg7vv/8+evTogZiYGAwaNAgff/wxIiIicPnyZaxbtw6DBg1Cq1atKnQ8iajqYrAjoipv0KBB+PLLL/Hpp59i0qRJCAsLw/z589G1a9e7tn/00UdhMBgwatQoyOVyDB48GNu3b8cbb7yBTp06QQiBunXrYujQoaWuwc3NDR9//DFOnz4NBwcHtG7dGuvWrYNcXnzyARcXF5w8eRK//PILrl+/jsDAQEyYMAHPPfccAKB37974+++/MWPGDHzyySdQKpWIjIzEM888A0A6pbpu3Tq88cYbeOqpp3D16lUEBASgc+fO8Pf3L/sBJCK7IRNCCFsXQUREREQVx3nsiIiIiOwEgx0RERGRnWCwIyIiIrITDHZEREREdoLBjoiIiMhOMNgRERER2QkGOzP67rvvEBYWBicnJ0RHR2Pnzp22LsmiZs6cidatW8Pd3R1+fn4YNGgQEhMTTdoIITB9+nQEBQXB2dkZXbt2xYkTJ0zaaDQaTJw4Eb6+vnB1dcXAgQNx8eJFkzY3b97EqFGj4OnpCU9PT4waNQq3bt0yaZOcnIwBAwbA1dUVvr6+mDRpErRarUX23dxmzpwJmUyGyZMnG5fx2N3bpUuXMHLkSPj4+MDFxQUtWrTAoUOHjO/z2N2dTqfDm2++ibCwMDg7OyM8PBwzZswwuc0Yj12RHTt2YMCAAQgKCoJMJsPq1atN3q9sxyouLg5dunSBs7MzatWqhRkzZsBWM5qVdOzy8/Px6quvomnTpnB1dUVQUBCeeOIJXL582WQb1fXYVZggs1iyZIlQKpXixx9/FPHx8eLFF18Urq6u4sKFC7YuzWJ69+4t5s+fL44fPy6OHDki+vfvL4KDg0V2draxzUcffSTc3d3FihUrRFxcnBg6dKgIDAwUmZmZxjbjxo0TtWrVEps2bRKHDx8W3bp1E82bNxc6nc7Ypk+fPqJJkyZi9+7dYvfu3aJJkybiwQcfNL6v0+lEkyZNRLdu3cThw4fFpk2bRFBQkJgwYYJ1DkYF7N+/X4SGhopmzZqJF1980bicx+7ubty4IUJCQsSYMWPEvn37RFJSkti8ebM4c+aMsQ2P3d29//77wsfHR/z9998iKSlJLF++XLi5uYnZs2cb2/DYFVm3bp144403xIoVKwQAsWrVKpP3K9OxysjIEP7+/mLYsGEiLi5OrFixQri7u4vPPvvMcgeoBCUdu1u3bokePXqIpUuXipMnT4o9e/aItm3biujoaJNtVNdjV1EMdmbSpk0bMW7cOJNlkZGR4rXXXrNRRdaXnp4uAIjt27cLIYQwGAwiICBAfPTRR8Y2arVaeHp6iu+//14IIX3BlUqlWLJkibHNpUuXhFwuF+vXrxdCCBEfHy8AiL179xrb7NmzRwAQJ0+eFEJIf4nI5XJx6dIlY5vFixcLlUolMjIyLLfTFZSVlSXq168vNm3aJLp06WIMdjx29/bqq6+Kjh073vN9Hrt769+/v3jqqadMlg0ePFiMHDlSCMFjV5I7w0llO1bfffed8PT0FGq12thm5syZIigoSBgMBjMeibK7Wyi+0/79+wUAY2cIj1358VSsGWi1Whw6dAi9evUyWd6rVy/s3r3bRlVZX0ZGBgAYb3ielJSEtLQ0k+OiUqnQpUsX43E5dOgQ8vPzTdoEBQWhSZMmxjZ79uyBp6cn2rZta2zTrl07eHp6mrRp0qQJgoKCjG169+4NjUZjcoqushk/fjz69++PHj16mCznsbu3NWvWoFWrVnjsscfg5+eHqKgo/Pjjj8b3eezurWPHjtiyZQtOnToFADh69Ch27dqFfv36AeCxK4vKdqz27NmDLl26QKVSmbS5fPkyzp8/b/4DYGYZGRmQyWTGeyvz2JUfg50ZXLt2DXq9vtg9Gv39/ZGWlmajqqxLCIEpU6agY8eOaNKkCQAY972k45KWlgZHR0fUqFGjxDZ+fn7FPtPPz8+kzZ2fU6NGDTg6Olba38GSJUtw+PBhzJw5s9h7PHb3du7cOcyZMwf169fHhg0bMG7cOEyaNAm//vorAB67krz66qsYPnw4IiMjoVQqERUVhcmTJ2P48OEAeOzKorIdq7u1KXxd2Y+nWq3Ga6+9hscffxweHh4AeOwqQmHrAuyJTCYzeS2EKLbMXk2YMAHHjh3Drl27ir1XnuNyZ5u7tS9Pm8oiJSUFL774IjZu3AgnJ6d7tuOxK85gMKBVq1b48MMPAQBRUVE4ceIE5syZgyeeeMLYjseuuKVLl+K3337DokWL0LhxYxw5cgSTJ09GUFAQRo8ebWzHY1d6lelY3a2We61bWeTn52PYsGEwGAz47rvv7tuex+7+2GNnBr6+vnBwcCiW7NPT04v9L8AeTZw4EWvWrMHWrVtRu3Zt4/KAgAAAxf/Hc/txCQgIgFarxc2bN0tsc+XKlWKfe/XqVZM2d37OzZs3kZ+fXyl/B4cOHUJ6ejqio6OhUCigUCiwfft2fPXVV1AoFPf83yKPHRAYGIhGjRqZLGvYsCGSk5MB8M9dSf73v//htddew7Bhw9C0aVOMGjUKL730krHXmMeu9Crbsbpbm/T0dADFexUri/z8fAwZMgRJSUnYtGmTsbcO4LGrCAY7M3B0dER0dDQ2bdpksnzTpk1o3769jaqyPCEEJkyYgJUrV+Lff/9FWFiYyfthYWEICAgwOS5arRbbt283Hpfo6GgolUqTNqmpqTh+/LixTUxMDDIyMrB//35jm3379iEjI8OkzfHjx5Gammpss3HjRqhUKkRHR5t/5yuoe/fuiIuLw5EjR4yPVq1aYcSIEThy5AjCw8N57O6hQ4cOxabVOXXqFEJCQgDwz11JcnNzIZeb/rXv4OBgnO6Ex670KtuxiomJwY4dO0ym8di4cSOCgoIQGhpq/gNQQYWh7vTp09i8eTN8fHxM3uexqwDrjNGwf4XTnfz8888iPj5eTJ48Wbi6uorz58/bujSLef7554Wnp6fYtm2bSE1NNT5yc3ONbT766CPh6ekpVq5cKeLi4sTw4cPvOh1A7dq1xebNm8Xhw4fFAw88cNch7c2aNRN79uwRe/bsEU2bNr3rkPbu3buLw4cPi82bN4vatWtXqqkT7uf2UbFC8Njdy/79+4VCoRAffPCBOH36tPj999+Fi4uL+O2334xteOzubvTo0aJWrVrG6U5WrlwpfH19xSuvvGJsw2NXJCsrS8TGxorY2FgBQHz++eciNjbWOHKzMh2rW7duCX9/fzF8+HARFxcnVq5cKTw8PGw2ZUdJxy4/P18MHDhQ1K5dWxw5csTk3w+NRmPcRnU9dhXFYGdG3377rQgJCRGOjo6iZcuWxmk/7BWAuz7mz59vbGMwGMQ777wjAgIChEqlEp07dxZxcXEm28nLyxMTJkwQ3t7ewtnZWTz44IMiOTnZpM3169fFiBEjhLu7u3B3dxcjRowQN2/eNGlz4cIF0b9/f+Hs7Cy8vb3FhAkTTIavV3Z3Bjseu3v766+/RJMmTYRKpRKRkZFi7ty5Ju/z2N1dZmamePHFF0VwcLBwcnIS4eHh4o033jD5x5THrsjWrVvv+nfc6NGjhRCV71gdO3ZMdOrUSahUKhEQECCmT59us+k6Sjp2SUlJ9/z3Y+vWrcZtVNdjV1EyIarq1MpEREREdDteY0dERERkJxjsiIiIiOwEgx0RERGRnWCwIyIiIrITDHZEREREdoLBjoiIiMhOMNiZmUajwfTp06HRaGxdSpXDY1d+PHblx2NXMTx+5cdjV348dvfGeezMLDMzE56ensjIyDC57x3dH49d+fHYlR+PXcXw+JUfj1358djdG3vsiIiIiOwEgx0RERGRnVDYugBr0+l0iI2Nhb+/P+Ry8+farKwsAMClS5eQmZlp9u3bMx678uOxKz8eu4rh8Ss/Hrvyq27HzmAw4MqVK4iKioJCUXJ0q3bX2B04cABt2rSxdRlEREREZbJ//360bt26xDbVrsfO398fgHRwAgMDbVwNERERUclSU1PRpk0bY4YpSbULdoWnXwMDA1G7dm0bV0NERERUOqW5hIyDJ4iIiIjsBIMdERERkZ1gsCMiIiKyE9XuGjsiIiJz0ev1yM/Pt3UZVMUplUo4ODiYZVsMdkRERGUkhEBaWhpu3bpl61LITnh5eSEgIAAymaxC22GwIyIiKqPCUOfn5wcXF5cK/2NM1ZcQArm5uUhPTweACk/FxmBHRERUBnq93hjqfHx8bF0O2QFnZ2cAQHp6Ovz8/Cp0WpaDJ4iIiMqg8Jo6FxcXG1dC9qTwz1NFr9lksCMiIioHnn4lczLXnycGOyIiIiI7wWBHRERE5da1a1dMnjy51O3Pnz8PmUyGI0eOWKwmANi2bRtkMlm1G7nMwRNERETVwP1O9Y0ePRoLFiwo83ZXrlwJpVJZ6vZ16tRBamoqfH19y/xZdH8MdhaQrzfgZo4WOoNAkJezrcshIiJCamqq8fnSpUvx9ttvIzEx0biscGRmofz8/FIFNm9v7zLV4eDggICAgDKtQ6XHU7EWsOfsdbT5cAue/uWgrUshIiICAAQEBBgfnp6ekMlkxtdqtRpeXl5YtmwZunbtCicnJ/z222+4fv06hg8fjtq1a8PFxQVNmzbF4sWLTbZ756nY0NBQfPjhh3jqqafg7u6O4OBgzJ071/j+nadiC0+ZbtmyBa1atYKLiwvat29vEjoB4P3334efnx/c3d3xzDPP4LXXXkOLFi3KdAxWrFiBxo0bQ6VSITQ0FLNmzTJ5/7vvvkP9+vXh5OQEf39/PProo8b3/vjjDzRt2hTOzs7w8fFBjx49kJOTU6bPtwYGOwtwVUkdoTkanY0rISIiaxBCIFers8lDCGG2/Xj11VcxadIkJCQkoHfv3lCr1YiOjsbff/+N48ePY+zYsRg1ahT27dtX4nZmzZqFVq1aITY2Fi+88AKef/55nDx5ssR13njjDcyaNQsHDx6EQqHAU089ZXzv999/xwcffICPP/4Yhw4dQnBwMObMmVOmfTt06BCGDBmCYcOGIS4uDtOnT8dbb71lPP188OBBTJo0CTNmzEBiYiLWr1+Pzp07A5B6O4cPH46nnnoKCQkJ2LZtGwYPHmzWY28uPBVrATXyr2CqYimQ5wKgm63LISIiC8vL16PR2xts8tnxM3rDxdE8/5xPnjwZgwcPNlk2depU4/OJEydi/fr1WL58Odq2bXvP7fTr1w8vvPACACksfvHFF9i2bRsiIyPvuc4HH3yALl26AABee+019O/fH2q1Gk5OTvj666/x9NNP48knnwQAvP3229i4cSOys7NLvW+ff/45unfvjrfeegsA0KBBA8THx+PTTz/FmDFjkJycDFdXVzz44INwd3dHSEgIoqKiAEjBTqfTYfDgwQgJCQEANG3atNSfbU3ssbMAd/0tTFD8iUcMtvmSExERlUerVq1MXuv1enzwwQdo1qwZfHx84Obmho0bNyI5ObnE7TRr1sz4vPCUb+Ets0qzTuFttQrXSUxMRJs2bUza3/n6fhISEtChQweTZR06dMDp06eh1+vRs2dPhISEIDw8HKNGjcLvv/+O3NxcAEDz5s3RvXt3NG3aFI899hh+/PFH3Lx5s0yfby3ssbMAJzdPAIAr1NDo9FApyn9rECIiqvyclQ6In9HbZp9tLq6uriavZ82ahS+++AKzZ89G06ZN4erqismTJ0Or1Za4nTsHXchkMhgMhlKvUziC9/Z17hzVW9bToEKIErfh7u6Ow4cPY9u2bdi4cSPefvttTJ8+HQcOHICXlxc2bdqE3bt3Y+PGjfj666/xxhtvYN++fQgLCytTHZbGHjsLcHHzAgC4Ig85al5nR0Rk72QyGVwcFTZ5WPIOGDt37sRDDz2EkSNHonnz5ggPD8fp06ct9nn3EhERgf3795ssO3iwbAMUGzVqhF27dpks2717Nxo0aGC8N6tCoUCPHj3wySef4NixYzh//jz+/fdfANLvuEOHDnj33XcRGxsLR0dHrFq1qgJ7ZRnssbMAByd36adMIDcnC95uKhtXREREVHb16tXDihUrsHv3btSoUQOff/450tLS0LBhQ6vWMXHiRDz77LNo1aoV2rdvj6VLl+LYsWMIDw8v9TZefvlltG7dGu+99x6GDh2KPXv24JtvvsF3330HAPj7779x7tw5dO7cGTVq1MC6detgMBgQERGBffv2YcuWLejVqxf8/Pywb98+XL161erHoTQY7CzB0RUGyCCHQE5WBuDPSRiJiKjqeeutt5CUlITevXvDxcUFY8eOxaBBg5CRkWHVOkaMGIFz585h6tSpUKvVGDJkCMaMGVOsF68kLVu2xLJly/D222/jvffeQ2BgIGbMmIExY8YAALy8vLBy5UpMnz4darUa9evXx+LFi9G4cWMkJCRgx44dmD17NjIzMxESEoJZs2ahb9++Ftrj8pOJyjhW14IuXryIOnXqICUlBbVr17bY5+RMD4Ar8nBs8FY0a9bSYp9DRETWpVarkZSUhLCwMDg5Odm6nGqrZ8+eCAgIwMKFC21dilmU9OeqLNmFPXYWopa5wFXkQZNt3f/VEBER2Zvc3Fx8//336N27NxwcHLB48WJs3rwZmzZtsnVplQ6DnYWoHZwBHaDNY7AjIiKqCJlMhnXr1uH999+HRqNBREQEVqxYgR49eti6tEqHwc5CtHJpyLguN8vGlRAREVVtzs7O2Lx5s63LqBI43YmF6BQuAAB9XqaNKyEiIqLqgsHOQnQKqcfOoGGPHREREVkHg52F6JVuAAChKf197IiIiIgqgsHOQnLcQ3HEUBc34W7rUoiIiKiasGmwmzlzJlq3bg13d3f4+flh0KBBSExMLHGdbdu2QSaTFXucPHnSSlWXTkL9cRikfQ/bXXrauhQiIiKqJmwa7LZv347x48dj79692LRpE3Q6HXr16oWcnJz7rpuYmIjU1FTjo379+laouPTcnKSbGWfzXrFERERkJTYNduvXr8eYMWPQuHFjNG/eHPPnz0dycjIOHTp033X9/PwQEBBgfBTewLeycFNJ9eRoGOyIiMh+dO3aFZMnTza+Dg0NxezZs0tcRyaTYfXq1RX+bHNtpyTTp09HixYtLPoZllSprrErvPect7f3fdtGRUUhMDAQ3bt3x9atW+/ZTqPRIDMz0/jIyrLOKNWQK//iP9VETLgx0yqfR0REVJIBAwbcc0LfPXv2QCaT4fDhw2Xe7oEDBzB27NiKlmfiXuEqNTW1Ut6ftTKpNMFOCIEpU6agY8eOaNKkyT3bBQYGYu7cuVixYgVWrlyJiIgIdO/eHTt27Lhr+5kzZ8LT09P4aNSokaV2wYSTgwG1ZNfhpb9mlc8jIiIqydNPP41///0XFy5cKPbevHnz0KJFC7RsWfZ7m9esWRMuLi7mKPG+AgICoFKprPJZVVWlCXYTJkzAsWPHsHjx4hLbRURE4Nlnn0XLli0RExOD7777Dv3798dnn3121/bTpk1DRkaG8REfH2+J8osR4V0wUPMeXhcvWOXziIiISvLggw/Cz88PCxYsMFmem5uLpUuX4umnn8b169cxfPhw1K5dGy4uLmjatOl9/12+81Ts6dOn0blzZzg5OaFRo0Z3vZ/rq6++igYNGsDFxQXh4eF46623kJ+fDwBYsGAB3n33XRw9etQ4QLKw5jtPxcbFxeGBBx6As7MzfHx8MHbsWGRnF00zNmbMGAwaNAifffYZAgMD4ePjg/Hjxxs/qzQMBgNmzJiB2rVrQ6VSoUWLFli/fr3xfa1WiwkTJiAwMBBOTk4IDQ3FzJlFZ+umT5+O4OBgqFQqBAUFYdKkSaX+7PKoFLcUmzhxItasWYMdO3agdu3aZV6/Xbt2+O233+76nkqlMkn3mZnWuROEi6cfjom6UGhkEEJAJpNZ5XOJiMiGtPcf/FeMgwpwKPjnWK8D9BpAJgeUzvffrqNrqT9GoVDgiSeewIIFC/D2228b/11avnw5tFotRowYgdzcXERHR+PVV1+Fh4cH1q5di1GjRiE8PBxt27a972cYDAYMHjwYvr6+2Lt3LzIzM02uxyvk7u6OBQsWICgoCHFxcXj22Wfh7u6OV155BUOHDsXx48exfv16423EPD09i20jNzcXffr0Qbt27XDgwAGkp6fjmWeewYQJE0zC69atWxEYGIitW7fizJkzGDp0KFq0aIFnn322VMftyy+/xKxZs/DDDz8gKioK8+bNw8CBA3HixAnUr18fX331FdasWYNly5YhODgYKSkpSElJAQD88ccf+OKLL7BkyRI0btwYaWlpOHr0aKk+t7xsGuyEEJg4cSJWrVqFbdu2ISwsrFzbiY2NRWBgoJmrqxjXgsETOoOARmeAk7JyDe4gIiIL+DCo7Os8tgBo/LD0/ORfwPIxQEhH4Mm1RW1mNwVyrxdfd3pGmT7qqaeewqeffopt27ahW7duAKTTsIMHD0aNGjVQo0YNTJ061dh+4sSJWL9+PZYvX16qYLd582YkJCTg/Pnzxo6aDz/8sNh1cW+++abxeWhoKF5++WUsXboUr7zyCpydneHm5gaFQoGAgIB7ftbvv/+OvLw8/Prrr3B1lQLuN998gwEDBuDjjz+Gv78/AKBGjRr45ptv4ODggMjISPTv3x9btmwpdbD77LPP8Oqrr2LYsGEAgI8//hhbt27F7Nmz8e233yI5ORn169dHx44dIZPJEBISYlw3OTkZAQEB6NGjB5RKJYKDg9GmTZtSfW552fRU7Pjx4/Hbb79h0aJFcHd3R1paGtLS0pCXl2dsM23aNDzxxBPG17Nnz8bq1atx+vRpnDhxAtOmTcOKFSswYcIEW+zCPbmKPIx1+AuTHFYimyNjiYioEoiMjET79u0xb948AMDZs2exc+dOPPXUUwAAvV6PDz74AM2aNYOPjw/c3NywceNGJCcnl2r7CQkJCA4ONjn7FhMTU6zdH3/8gY4dOyIgIABubm546623Sv0Zt39W8+bNjaEOADp06ACDwWAyJ27jxo1NZs4IDAxEenp6qT4jMzMTly9fRocOHUyWd+jQAQkJCQCk071HjhxBREQEJk2ahI0bNxrbPfbYY8jLy0N4eDieffZZrFq1CjqdZTOBTXvs5syZA0AaOn27+fPnY8yYMQCkETC3/7K1Wi2mTp2KS5cuwdnZGY0bN8batWvRr18/a5VdKnKDFq8rpesSLuR9AV83XuxJRGT3Xr9c9nUcbvv3IXKAtA3ZHf0uk+MqVtdtnn76aUyYMAHffvst5s+fj5CQEHTv3h0AMGvWLHzxxReYPXs2mjZtCldXV0yePBlarbZU2xZCFFt256VIe/fuxbBhw/Duu++id+/e8PT0xJIlSzBr1qwy7UdJlzndvlypVBZ7z2AwlOmz7vyc2z+7ZcuWSEpKwj///IPNmzdjyJAh6NGjB/744w/UqVMHiYmJ2LRpEzZv3owXXngBn376KbZv316sLnOx+anY+7nzIs9XXnkFr7zyioUqMiNHN+PTnOwMoKaHDYshIiKrKMM1b3floCi63s6c273NkCFD8OKLL2LRokX45Zdf8OyzzxpDys6dO/HQQw9h5MiRAKRr5k6fPo2GDRuWatuNGjVCcnIyLl++jKAg6bT0nj17TNr8999/CAkJwRtvvGFcdudIXUdHR+j1+vt+1i+//IKcnBxjr91///0HuVyOBg0alKre+/Hw8EBQUBB27dqFzp07G5fv3r3b5JSqh4cHhg4diqFDh+LRRx9Fnz59cOPGDXh7e8PZ2RkDBw7EwIEDMX78eERGRiIuLq5cI5BLo1IMnrBLChV0cIACeqizbwGoY+uKiIiI4ObmhqFDh+L1119HRkaG8QwZANSrVw8rVqzA7t27UaNGDXz++edIS0srdbDr0aMHIiIi8MQTT2DWrFnIzMw0CXCFn5GcnIwlS5agdevWWLt2LVatWmXSJjQ0FElJSThy5Ahq164Nd3f3YtOcjBgxAu+88w5Gjx6N6dOn4+rVq5g4cSJGjRplvL7OHP73v//hnXfeQd26ddGiRQvMnz8fR44cwe+//w4A+OKLLxAYGIgWLVpALpdj+fLlCAgIgJeXFxYsWAC9Xo+2bdvCxcUFCxcuhLOzs8l1eOZWaaY7sTsyGfJk0ogmbY51RuISERGVxtNPP42bN2+iR48eCA4ONi5/66230LJlS/Tu3Rtdu3ZFQEAABg0aVOrtyuVyrFq1ChqNBm3atMEzzzyDDz74wKTNQw89hJdeegkTJkxAixYtsHv3brz11lsmbR555BH06dMH3bp1Q82aNe865YqLiws2bNiAGzduoHXr1nj00UfRvXt3fPPNN2U7GPcxadIkvPzyy3j55ZfRtGlTrF+/HmvWrDHeytTNzQ0ff/wxWrVqhdatW+P8+fNYt24d5HI5vLy88OOPP6JDhw5o1qwZtmzZgr/++gs+Pj5mrfF2MlGa86F25OLFi6hTpw5SUlLKNbVKWVx7rz589enY0XkxOj9Qua4BJCKi8lGr1UhKSkJYWBicnJxsXQ7ZiZL+XJUlu7DHzoI0cmkm7vw869zGjIiIiKo3BjsLyldIwU6Xx1OxREREZHkMdhakU0gjYw1q9tgRERGR5THYWZBeKQ2/Fprs+7QkIiIiqjgGOwsyFM5lp2GPHREREVkeg50lFQQ7eX45bgpNRESVWlnvXkBUEnP9eeIExRYkU7kDAOT5PBVLRGQvHB0dIZfLcfnyZdSsWROOjo73vLUV0f0IIaDVanH16lXI5XI4OjpWaHsMdhZkcAvAWUMgbgi3+zcmIqIqQS6XIywsDKmpqbh8uRz3hiW6CxcXFwQHB0Mur9jJVAY7C7rVeDQe3xOJBgo3DLN1MUREZDaOjo4IDg6GTqe77z1Nie7HwcEBCoXCLD2/DHYW5OYkHd5stc7GlRARkbnJZDIolUoolUpbl0JkxMETFuSqKgh2GgY7IiIisjz22FlQjZvH8Y/jq7hi8IYQvXhxLREREVkUg50FOStlaChPgbvIgzrfAGdHB1uXRERERHaMwc6CnAIjMUo7DTeFK+Zp8hnsiIiIyKIY7CxI5uSJI45RyFLrkKPRA+62roiIiIjsGQdPWJibiiNjiYiIyDrYY2dhj8n+RY7DTeRkNwHgaetyiIiIyI4x2FnYePWPUCk12JX5JIAQW5dDREREdoynYi1MLXcGAGhyM2xcCREREdk7BjsL08hdAAD5eVk2roSIiIjsHYOdhWkVrgAAfS6DHREREVkWg52F6QqDnTrTxpUQERGRvWOwszB9QbATmmwbV0JERET2jsHOwgyObgAAoeGpWCIiIrIsBjtLKwh2cm2OjQshIiIie8dgZ2EyVUGwy+epWCIiIrIsBjsLk6ukG8Q66NhjR0RERJbFYGdhcmcPAIBSz2BHRERElsVgZ2FKZ6nHzlGXa+NKiIiIyN7xXrEWpnDzwVXhiQzhZOtSiIiIyM4x2FmYvPEgtF7tBpkMeFAIyGQyW5dEREREdoqnYi3MTSVlZyGAXK3extUQERGRPWOwszAnpRwOcqmXLlujs3E1REREZM94KtbCZFlpWOY4AwaDHlnqLvD3sHVFREREZK8Y7CxNJkc0EmCQyRCnzrd1NURERGTHGOwszbkG3nN5DadvCTynYbAjIiIiy+E1dpamcESsW2fsMDRHttZg62qIiIjIjjHYWYGbkxIAkK3m4AkiIiKyHJ6KtYJ2ugMIcEiCLjMAQG1bl0NERER2isHOCh65/gP8lRew6lYrANG2LoeIiIjsFE/FWoHOwRUAoFdn2bgSIiIismcMdlagU0rBTjDYERERkQUx2FmBQekmPdFk27YQIiIismsMdlYgHKUeO2gZ7IiIiMhyGOysQKZyBwDI8xnsiIiIyHIY7KxA7iSdinXIz7FxJURERGTPGOysQK7yAAAo9Qx2REREZDkMdlagcJZ67JS6XBtXQkRERPaMwc4KlC5Sj52TgT12REREZDkMdlagcvEEADiJPOgNwsbVEBERkb1isLMClZvUY+cGNXK0OhtXQ0RERPaKwc4KHJ09oRFK5MMBORoGOyIiIrIMha0LqBbqtEU7h0W4mZuPTWod4GnrgoiIiMgescfOGmQyuKqkDJ3NHjsiIiKyEAY7K3FjsCMiIiIL46lYazDo8X7ue9A5ZiErayGAmrauiIiIiOwQg501yB3QXBsLpTwff+fctHU1REREZKdseip25syZaN26Ndzd3eHn54dBgwYhMTHxvutt374d0dHRcHJyQnh4OL7//nsrVFsxiwKmYoJ2Im4aXG1dChEREdkpmwa77du3Y/z48di7dy82bdoEnU6HXr16ISfn3ndoSEpKQr9+/dCpUyfExsbi9ddfx6RJk7BixQorVl52CTX74W9DDDL0jrYuhYiIiOyUTU/Frl+/3uT1/Pnz4efnh0OHDqFz5853Xef7779HcHAwZs+eDQBo2LAhDh48iM8++wyPPPKIpUsut8LBE1kcPEFEREQWUqlGxWZkZAAAvL2979lmz5496NWrl8my3r174+DBg8jPz7dofRURrk1EH/l+KLMu2roUIiIislOVZvCEEAJTpkxBx44d0aRJk3u2S0tLg7+/v8kyf39/6HQ6XLt2DYGBgSbvaTQaaDQa4+usrCzzFl5KnS7OxeOOu/H7TScAPW1SAxEREdm3StNjN2HCBBw7dgyLFy++b1uZTGbyWghx1+WANEDD09PT+GjUqJF5Ci4j4VgwaEKbbZPPJyIiIvtXKYLdxIkTsWbNGmzduhW1a9cusW1AQADS0tJMlqWnp0OhUMDHx6dY+2nTpiEjI8P4iI+PN2vtpeboDgCQM9gRERGRhdj0VKwQAhMnTsSqVauwbds2hIWF3XedmJgY/PXXXybLNm7ciFatWkGpVBZrr1KpoFKpjK8zMzMrXng5yJzcAAAOunuP+CUiIiKqCJv22I0fPx6//fYbFi1aBHd3d6SlpSEtLQ15eXnGNtOmTcMTTzxhfD1u3DhcuHABU6ZMQUJCAubNm4eff/4ZU6dOtcUulJqDk9Rjp2SwIyIiIguxabCbM2cOMjIy0LVrVwQGBhofS5cuNbZJTU1FcnKy8XVYWBjWrVuHbdu2oUWLFnjvvffw1VdfVeqpTgBA4ewBAFDqcm1cCREREdkrm5+KvZ8FCxYUW9alSxccPnzYAhVZjrIg2Dka2GNHREREllEpBk9UB44uUrBzNuRBpzfYuBoiIiKyRwx2VuLo6gkAcJOpkaPR27gaIiIiskcMdlZSeCrWFXnI1vK2YkRERGR+DHbWopKmO3GVqZGtZrAjIiIi82Ows5aCCYrdkIdsTeW9py0RERFVXQx21lLQY6dCPnvsiIiIyCIY7KzFLQAjAtYgUrMA2Rw8QURERBbAYGctcjlUTi4AZMjRsMeOiIiIzI/BzorcVNJ80FkMdkRERGQBDHZWNOzaN5irnAXFrSRbl0JERER2iMHOiiKy96GXwyHIc67YuhQiIiKyQza9V2x1cyjkGWw9kQx3BNi6FCIiIrJD7LGzopTgh7BY3x1pBi9bl0JERER2iMHOitwLBk9kc/AEERERWQCDnRXVzL+EDvI4uOYk27oUIiIiskMMdlYUcW4+fnecibZZm21dChEREdkhBjsrkhfcVsxBl2vjSoiIiMgeMdhZkcLZAwCg1OfYuBIiIiKyRwx2VqR0kYKdo549dkRERGR+DHZWpCzosXMWedDqDDauhoiIiOwNg50VqVw9AQBuUCOHU54QERGRmTHYWZGDk9Rj5yrL41x2REREZHYMdtZUMCrWFWoGOyIiIjI7BjtrcpSCnRt77IiIiMgCGOysiT12REREZEEMdtbk6A4AcJOpkZ2ntXExREREZG8Y7KypoMcOADS5WTYshIiIiOwRg501KZygLzjk2twMGxdDRERE9obBzppkMnzc6E9EqufjiqGGrashIiIiO8NgZ2Uy95pQQ4Ucrd7WpRAREZGdYbCzMneVAgA4KpaIiIjMjsHOytqkLsIs5Rz43IqzdSlERERkZxjsrCzk5m484rATHrkXbF0KERER2RmFrQuoblLDHsG81DBcQZitSyEiIiI7w2BnZVkNHsYPO2shUu9u61KIiIjIzvBUrJW5cfAEERERWQh77KzM05CBprJzkKk9bF0KERER2Rn22FmZ7+kl+Ev1JkbpV9q6FCIiIrIzDHZWpnSWeuqcRR40Ok5STERERObDYGdlKhcp2LlBjWw1r7MjIiIi82GwszK5kzQa1lWWxwEUREREZFYMdtbm6AagoMeOwY6IiIjMiMHO2lQFPXbI46lYIiIiMisGO2sr6LFzlamRo2WwIyIiIvNhsLM2VdGp2Cz22BEREZEZMdhZW0GPnUqWj5y8PBsXQ0RERPaEwc7aVEX3iM3PzbRhIURERGRvGOyszUGJfJkjAECbw2BHRERE5sNgZwP5Di4AAL2awY6IiIjMh8HOBvIVrgAY7IiIiMi8GOxsYFPrH9FG/S0S5PVtXQoRERHZEYWtC6iOZF4hSMctZGplti6FiIiI7Ah77GzAVSXl6Wx1vo0rISIiInvCYGcDYWnr8Y7iFzTIOWTrUoiIiMiOMNjZgG/6bjyp2IAwTYKtSyEiIiI7wmBnA9qwHvhWNxD7dQ1sXQoRERHZEQ6esAF544H49E9XOBhkEEJAJuMgCiIiIqo49tjZQOHgCb1BQJ1vsHE1REREZC/KFexSUlJw8eJF4+v9+/dj8uTJmDt3rtkKs2cuQo1QWRpqy9KRrdHZuhwiIiKyE+UKdo8//ji2bt0KAEhLS0PPnj2xf/9+vP7665gxY4ZZC7RH8lPrsE01BR8pfmSwIyIiIrMpV7A7fvw42rRpAwBYtmwZmjRpgt27d2PRokVYsGBBqbezY8cODBgwAEFBQZDJZFi9enWJ7bdt2waZTFbscfLkyfLshu04ugEA3GRq5DDYERERkZmUa/BEfn4+VCoVAGDz5s0YOHAgACAyMhKpqaml3k5OTg6aN2+OJ598Eo888kip10tMTISHh4fxdc2aNUu9bqWgkoKdK9S4pmawIyIiIvMoV7Br3Lgxvv/+e/Tv3x+bNm3Ce++9BwC4fPkyfHx8Sr2dvn37om/fvmX+fD8/P3h5eZV5vUqjoMfOVZaH8+yxIyIiIjMp16nYjz/+GD/88AO6du2K4cOHo3nz5gCANWvWGE/RWlJUVBQCAwPRvXt347V+VYrKHQDgBp6KJSIiIvMpV49d165dce3aNWRmZqJGjRrG5WPHjoWLi4vZirtTYGAg5s6di+joaGg0GixcuBDdu3fHtm3b0Llz57uuo9FooNFojK+zsrIsVl+pFfbYIQ9ZvF8sERERmUm5gl1eXh6EEMZQd+HCBaxatQoNGzZE7969zVrg7SIiIhAREWF8HRMTg5SUFHz22Wf3DHYzZ87Eu+++a7GayqXgGjsHmYAmL9vGxRAREZG9KNep2Iceegi//vorAODWrVto27YtZs2ahUGDBmHOnDlmLfB+2rVrh9OnT9/z/WnTpiEjI8P4iI+Pt2J196B0NT7V5mTYsBAiIiKyJ+UKdocPH0anTp0AAH/88Qf8/f1x4cIF/Prrr/jqq6/MWuD9xMbGIjAw8J7vq1QqeHh4GB/u7u5WrO4e5HJo5dIpa11eJTg1TERERHahXKdic3NzjQFp48aNGDx4MORyOdq1a4cLFy6UejvZ2dk4c+aM8XVSUhKOHDkCb29vBAcHY9q0abh06ZKxd3D27NkIDQ1F48aNodVq8dtvv2HFihVYsWJFeXbDpvIVLnDU5kKvzrR1KURERGQnyhXs6tWrh9WrV+Phhx/Ghg0b8NJLLwEA0tPTTeaXu5+DBw+iW7duxtdTpkwBAIwePRoLFixAamoqkpOTje9rtVpMnToVly5dgrOzMxo3boy1a9eiX79+5dkNm9IpXAHtNRjUvMaOiIiIzKNcwe7tt9/G448/jpdeegkPPPAAYmJiAEi9d1FRUaXeTteuXSGEuOf7d97F4pVXXsErr7xSnpIrHYOjG5ALQMtTsURERGQe5Qp2jz76KDp27IjU1FTjHHYA0L17dzz88MNmK86eCceCa/007LEjIiIi8yhXsAOAgIAABAQE4OLFi5DJZKhVq5ZVJie2F+dj3sdjy2Lh6l4HL9u6GCIiIrIL5RoVazAYMGPGDHh6eiIkJATBwcHw8vLCe++9B4PBYO4a7ZKyZgOcFbVwVeto61KIiIjITpSrx+6NN97Azz//jI8++ggdOnSAEAL//fcfpk+fDrVajQ8++MDcddodV5UDACBbzVuKERERkXmUK9j98ssv+OmnnzBw4EDjsubNm6NWrVp44YUXGOxKocbV/XhJ8QeO68IgRC/IZDJbl0RERERVXLlOxd64cQORkZHFlkdGRuLGjRsVLqo6cEvbjxcVK9FNdhi5Wr2tyyEiIiI7UK5g17x5c3zzzTfFln/zzTdo1qxZhYuqDhR1WmGhvif2GhojR8PTsURERFRx5ToV+8knn6B///7YvHkzYmJiIJPJsHv3bqSkpGDdunXmrtEuyer3wKcOemTm6/CiRgc/WxdEREREVV65euy6dOmCU6dO4eGHH8atW7dw48YNDB48GCdOnMD8+fPNXaPdclNJuZoDKIiIiMgcyj2PXVBQULFBEkePHsUvv/yCefPmVbgwu6fXoZZjDvTI4KlYIiIiMotyBzuqoIsHsDxrFJIc/XFK09PW1RAREZEdKNepWDIDlRsAwE2mZo8dERERmQWDna04SsHOFWpkM9gRERGRGZTpVOzgwYNLfP/WrVsVqaV6UbkDAFxkGuSoNTYuhoiIiOxBmYKdp6fnfd9/4oknKlRQtVHQYwcAmpwsGxZCRERE9qJMwY5TmZiRQgW9zAEOQg9dXqatqyEiIiI7wGvsbEUmQ76DKwBAp2awIyIioopjsLMhnVI6HWvIy7ZxJURERGQPGOxsyKCUeuyg5TV2REREVHEMdjZkKOixg4Y9dkRERFRxDHa2VDAyVpbPYEdEREQVx2BnQzInKdg55OfYuBIiIiKyBwx2NiQvmKRYwWBHREREZlCmeezIvHQxL2Lw0UZIEX6YbBCQy2W2LomIiIiqMAY7G3IOaojD4gIAIEerg7uT0sYVERERUVXGU7E2pFLIoSjopcvW6GxcDREREVV17LGzIdnVRIxT/YNzGi/kaDrbuhwiIiKq4thjZ0uXYzFV/IphDluRpWaPHREREVUMg50t+dTDv8ou2GVoghyN3tbVEBERURXHU7G2VKc1vvN+DQezbqKlJt/W1RAREVEVxx47G3NVSdk6mz12REREVEEMdjbmoQI8kI1sNXvsiIiIqGJ4KtaWMi7h69M9oVU5YK5mn62rISIioiqOPXa25Ogq/ZDpkZeXZ+NiiIiIqKpjsLMlRzfj0/y8DBsWQkRERPaAwc6WHBTQyZ0AAPq8bBsXQ0RERFUdg52N6RQuAAC9OtPGlRAREVFVx2BnY3qldDrWoM6ycSVERERU1THY2ZhBKQ2gkGl5KpaIiIgqhsHOxkThAAoGOyIiIqogBjsbc3T1BACoszOQkcdJiomIiKj8GOxszMnFAwDggjzsT7ph42qIiIioKmOwszWVdCrWFWrsPnvNxsUQERFRVcZgZ2uO7gAAN5kae85et3ExREREVJUx2NmasccuDyfTsnA9W2PjgoiIiKiqYrCztaaPASP+wPYajwAA9p7jdXZERERUPgx2tuZbH6jfE3UaNAcAXmdHRERE5cZgV0m0r+sLALzOjoiIiMpNYesCqr2sNOD0JnQQjpDL3HDuWg7SMtQI8HSydWVERERUxbDHztaunwHWTIDLfx+haS1psuI953g6loiIiMqOwc7WvIIBzzpAuxfQrq4PAGD3GZ6OJSIiorJjsLM1r2DgxaNAm2eN19ntPnsdQggbF0ZERERVDYNdZSB3AAC0Dq0BhVyGS7fykHIjz8ZFERERUVXDYFdZ6HVwSViBj2qsAcBpT4iIiKjsGOwqi/QTwKqxGJyzDCGyNOw5x+vsiIiIqGwY7CqLwOZA/V6QQ48XHNbwOjsiIiIqMwa7yqTzKwCAwQ47ocpOwdmr2TYuiIiIiKoSBrvKpE5roO4DUMqKeu2IiIiISovBrrLp8ioA4FGH7UhIiLdxMURERFSVMNhVNsHtkBUYA0eZHi2SF8Bg4HV2REREVDo2DXY7duzAgAEDEBQUBJlMhtWrV993ne3btyM6OhpOTk4IDw/H999/b/lCrcy5x+sAgEFiC06fPWXjaoiIiKiqsGmwy8nJQfPmzfHNN9+Uqn1SUhL69euHTp06ITY2Fq+//jomTZqEFStWWLhS61KEd0KiqilUMh3yd8y2dTlERERURShs+eF9+/ZF3759S93++++/R3BwMGbPng0AaNiwIQ4ePIjPPvsMjzzyiIWqtAGZDGcavoCII8+jwcU/gKzpgLu/rasiIiKiSq5KXWO3Z88e9OrVy2RZ7969cfDgQeTn59uoKssIadUPhwz14Si0MPz3la3LISIioiqgSgW7tLQ0+Pub9lz5+/tDp9Ph2rW734JLo9EgMzPT+MjKyrJGqRXWKMgTP8sfAwCIgz8D2VdtXBERERFVdlUq2AGATCYzeV14d4Y7lxeaOXMmPD09jY9GjRpZvEZzkMtl0Ic/gL2GhogLGAzIHWxdEhEREVVyVSrYBQQEIC0tzWRZeno6FAoFfHx87rrOtGnTkJGRYXzEx1edueHa16uJYdo38RlGAy7eti6HiIiIKjmbDp4oq5iYGPz1118myzZu3IhWrVpBqVTedR2VSgWVSmV8nZmZadEazal9XR8AMhw4fwManR4qBXvtiIiI6N5s2mOXnZ2NI0eO4MiRIwCk6UyOHDmC5ORkAFJv2xNPPGFsP27cOFy4cAFTpkxBQkIC5s2bh59//hlTp061RfkWV8/PDb5uKmh0Bpw+uBlYMgLIu2XrsoiIiKiSsmmwO3jwIKKiohAVFQUAmDJlCqKiovD2228DAFJTU40hDwDCwsKwbt06bNu2DS1atMB7772Hr776yr6mOrmNTCYr6LUTCNgxDTj5N7DP/iZkJiIiIvOw6anYrl27Ggc/3M2CBQuKLevSpQsOHz5swaoql5i6Plhz9DJ+cRyOlyNTgGZDbV0SERERVVJVavBEdST12AHfX22M3D6fA95hNq6IiIiIKisGu0ou2NsFtbycka8XOHj+prQwOx34fQhw/j/bFkdERESVCoNdJSeTyRBT0Gu3++x1aeHur4DTG4AF/YD5/YFz24ESTmkTERFR9cBgVwUUno7dc64g2LUZC7R6GnBwBC7sAn4dCMzrA5zZwoBHRERUjTHYVQGFPXZxF28hU50PeAUDD34OTDoCtHkOcFABKXuB3wYDP3UHTm1gwCMiIqqGGOyqgEBPZ4T5usIggP3nbhS94VkL6PcJMPkY0G48oHAGLh0CFg0B5nYBEv4GDAbbFU5ERERWxWBXRRS7zu527gFAnw+ByXFAhxcBpSuQehRYOgL4JhrY/C5g0Fu5YiIiIrI2Brsqor0x2F27dyO3mkDPGVLA6/Qy4OgO3DgHnNkEyG+7Hdn1szxVS0REZIeq1L1iq7N24VKwO5mWhRs5Wni7Ot67sasP0P1toONLwOmNgPy2++hqsoDvYgA3P+DZf6WfREREZBfYY1dF+LqpEOHvDgDYe+4up2PvRuUONHkEaDSwaNmVeECukEbUutYsWn50CZC0A9BpzVg1ERERWRN77KqQmLo+SLyShd1nr6Ff08DybSS4LfDKWeBWMiCTSct0GmDd/wBNpnT6NrwLUK87UK+HNAKXiIiIqgQGuyqkfV0fLNh9Hr/vS8a+czfQtLYnmtbyRLPanmgU6AlnR4f7bwQAlM5AzYii1+pMIPJB6bRt7jXg5N/SAwB8I6SAV78HENweUDqZf8eIiIjILGRCVK+r6C9evIg6deogJSUFtWvXtnU5ZZKr1eGx7/fgxOXMYu/JZUADf3c0KQh6TWt5omGgB5yUpQx7gDQ1StpR4MxmabLjlP2AuG00rcIZCOsE1OspBT3vcDPsFREREZWkLNmFwa4KSs9S4/ilDMRdzETcpVs4ejEDV7M0xdo5yGXo3zQQnz7WDCpFGQJeobyb0u3KzmySgl5WatF7MjnwShLg7FX+HSEiIqL7Kkt24anYKsjP3QkPRDrhgUh/47IrmWrEXczAsUsZiLt4C3GXMnAtW4s1Ry8jV6vHnJEtoXQo41gZ5xpA40HSQwggPR44vUnq0ZPJTEPd70MAR1eg2xuAbz1z7CYRERGVEXvs7JQQAjtPX8Ozvx6ERmdA/6aB+HJYCyjKGu7uxaAvmhsv5zrwWT1AGICXTgCeBcf1cqw0+tavUdFADSIiIiqTsmQXTndip2QyGTo3qIkfRkVD6SDD2rhU/O+PY9AbzJTjb5/w2NkLeGoj0OejolAHAP9+AMxpD3zZHNjyHpB+0jyfTURERHfFYGfnukb44dvHW0Ihl2FV7CW8sSoOBnOFu0JyB6BOa6Dd80XLhAAcXQCFE3DrArDzM+C7tsD3HYH/vgIyL5u3BiIiImKwqw56NQ7A7GEtIJcBSw6k4N2/TsDiZ+BlMmDIr9IAi0fnAQ36ShMjp8UBm94CPm8ELHgQOPwrkHfLsrUQERFVExw8UU082CwImnwDpv5xFL/suQAnpQNe6xsJmaWvfXN0ke5+0eQRIPcGcGIVELccSN4DnN8pPdZOBRr0ApoOARr0ARQl3C6NiIiI7onBrhp5JLo2NDoDXl8Vhx92nINK6YApPRtYrwAXb6D109Lj5gXg+B/AseXA1QQg4S9pxO3U00XBbn5/6b1H5wHhXaVlieuBXV8ACpV0S7RaLYFarYDAZtLEy0RERNUYg10183jbYGh0erz7Vzy+2nIaTko5XuhqmelJbuVq8f32c3CQAy/1aGA6IrdGCNDpZaDjFODKceDYMkCvBZw8itrk3QBy77gvbuYlIGVv0evjf0g/5Qpp9G3tVkCtaCns+dY3HeRBRERk5xjsqqEnO4RBnW/Ax+tP4pP1iVApHPB0xzCzbV9vEFi0PxmzNibiVm4+AOB6thYzBzctfupXJgMCmkqPOz2+FNDmAJ51ipbV6w4MWQjo1NL9bi8dBi4dBLKvAGnHpMfBeVJbR3cgqAVQt5sUIgvl3gCcvAA5LzElIiL7wmBXTT3ftS7U+Xp8ueU03vs7Hk5KOUa0Danwdvedu47pf8UjIVW67Vm4ryvOX8/BkgMp8HFzxP96R5Z+Y17BxZfVCJUetxNC6sm7eBC4dEh6XI4FtFnSNXwOjqbB7osmUjCceAjwLgi0J1ZJt1Bz9QU8g4GQGNOpW4iIiKoABrtqbHKP+lDr9Phh+zm8seo4cjQ6PBpdB96uZR+8cPlWHj5cl4C/j0m3HfN0VuLlXg3weJtgLD90EdNWxuHbrWfh7aoya+8gAKnXz7O29Gg8SFqm1wFXT0ohz7VmUVttLpCfIz138SlafnYrcPgX0+3WCAVCOwKhnYCQDoBXHRAREVVmvPNENSeEwLt/xWPB7vMApIwUVccL3SL80C3SD42DPEocOavO1+PHHefw7bYzUOcbIJdJ1/FN6RlhEhC/3XoGn25IBADMHtoCg6JqWXS/SqTPB3KuAe4BRXfEOLkWSNknLU9PAFKPSHfSuJ1XiBTyQjtKDwY9IiKygrJkFwY7ghACP+1MwsrYS8ZTqIX83FXoGlET3SL80LG+L9ydlMZ1Npy4gg/WxSPlRh4AoE2oN94Z2AiNgzzv+hkz/o7H/P/OQyGX4cfRrdAtws/yO1de6kwp6J3fCZzfBVw+Agi9SRNd+8lIbfUq6ni72KZGIiKqFhjsSsBgV7LUjDxsS7yKrSfTsevMNeRqi8KMQi5D61BvdImoiV2nr2HXmWsAgAAPJ7zevyEGNAsssXfPYBB4adkR/HnkMpyUcvz+TDtEh9Sw+D6ZhSYLSC4Iehf+g7h0GB+7vIzvr7dAj4b+eLtFNoJ3TAUaDQS6v23raomIyI4w2JWAwa70NDo9DiTdxNbEdGw9mY5z13JM3ndUyPFc53A837UuXBxLd7mmVmfAs78exPZTV+HprMTycTFo4O9uifItRgiBVxbtxpq4dGggnW6eoFiNqYplyK3XHy4jFxU2BLZ9JE3BEhwDqNxsWDUREVVVDHYlYLArv/PXcrAtMR07T1+Dl4sjXuxeH8E+ZT8NmavVYcRP+xCbfAsBHk744/kY1K5RdU5n/rTzHN5fmwCFXIaPHmmGzfFXsPvEWbSTxyNb7oHItn0w4YF68FanAF+3lFaSK4CAZtL8fR61pIdnraLnbn6cc4+IiO6Kwa4EDHaVw61cLR77fg9Op2cj3NcVy8fFwMdNZeuy7mv32WsY9fN+6A0C7wxohCc7SCN8Y5Nv4uP1J7H33A0AgJtKgf+1VuDx/JVQXtghzblXErkCcA8EPIKkefrc/aXlKQeArFQgoAngHW7JXSMiokqKwa4EDHaVR2pGHh75bjcuZ6jRrLYnFj3bDm6qyjsDz6VbeRjw9S7cyNFicFQtzBrS3OSaQiEEdpy+hk/Wn8SJy9IgFF83R0x8oD6G1xdwvHoMyLwMZFyU5t3LvAxkXJKC2+0DM15Ple6xCwCrXwCO/C5dt1c4F1/qMWDBg4BLDWnKFidPQCYHICsa5Wt8ftvPQd8CzgXXNCb8BVzYA9R9AKjfQ1qmyQZObwQcXQGli3QXEN8GvFUbEZGNlSW7VN5/RcnuBXo649en2+Kx73fj2MUMjFt4CD+PaQWVovKdklTn6/H8b4dwI0eLxkEe+PAud9GQyWTo0qAmOtXzxd9xqZi1MREXrufinTUn8JO3M6b2aoWBbYOKDzAx6KU7Z2RcArLTikIdANQIA+q0lX4Wyr0OaDKkx83zpd8J3RdFz89tBw78KIW4wmCXeRn440nTdWQO0q3agpoDQVFAYBTg3xhQOpX+c4mIyGrYY0c2dyTlFh7/cS9ytXr0buyPmYOblWuSZEsRQuCVP45h+aGLqOGixJoJHUs1xUm+3oAlB1Lw1ZbTuJqlAQAMaVUb7w9qCkdFBW5nlp8H3EopupeuOkMaqCFVW/BcFBZf9LzpkKLQeHKddM/dsC7SbdoA4PpZYM0kaQJnbS6Qe634vXqBgvvyNiwIei2AZkM5MISIyIJ4KrYEDHaV087TV/HUggPI1wu4qxR4rks4nuoYVurRtpa0cO8FvLX6OOQy4Nen2qJjfd8yrZ+r1WHujnP4astpGAQQE+6D70dGw9NFaaGKzaTwVm2Xj0i3aEst+Hl72JPJgWkXpZ4/ADi9SZrYObiddIqYiIgqjMGuBAx2lde+c9cx4+944/Vpfu4qvNSzAR6Lrg2FQwV6uCrg0IUbGDZ3L/L1Aq/1jcS4LnXLva1/T17BxEWxyNHqUbemK+aPaVOuUcU2JYR0jWBh0Mu5Bgz8quj9n3oAFw8Ag74HWgyXluXeAPRa6U4fRERUZgx2JWCwq9wMBoG/jl3GpxsScfGmdEeLujVd8UqfSPRq5F/iBMjmlp6pRv+vd+Fqlgb9mwbim8ejKvz58Zcz8fQvB5CaoYa3qyN+fCIa0SHeZqrYxoQA1k6Rrt8btVK61y4A7P4G2PiGNKo3uL3Um+dTT7olm3sgp3khIroPBrsSMNhVDRqdHr/vTcbX/57Gzdx8AEB0SA1M6xuJVqGWD0JanQHDf9yLQxduooG/G1a90AGuZhqxeyVTjad/OYDjlzLhqJDjs8eaY2DzILNsu1L65zVg3/cwXut3O7lCmuLFs4708Cr46dcIqNPa6qVWKtnpUlgunPpGkw1sfgdQeQAPvAXIC3qxU48B2mxpucpdGs3soJJOk8sdpJ8y+W0jpqsBba402lx9C9BpAJ367j9dfYEmjxStd2iBdC/pRg9Jc0sCQPZVIO+mdGxVboDStejYE1kJg10JGOyqlkx1PuZuP4efdp2DOt8AAOjZyB+v9olAPT/L3bHizdVx+G1vMtydFPhrQkeE+rqadfu5Wh0mLT6CzQlXAAAv92yACQ/Us2qPpFXl3QJS9gPJu4GLB6V5/TIvAQbd3dtH9AeGF9zBw2AAPm8o/aP69CbApSDYH1sOXD4sBRonD+mnqy/g6ge41ZR+VoXRu3odcP00kHYcuBIHpMVJz3PSgfYTgV7vS+1uJQOzm0qh7a30ovUXDQNO/VOKD5IVhb3mw4tOoWtzgFkNpedTE4umt/n7JeD4iqJ1jcRtGV2YDtyp1wMY8ktR0596SOs+Ok8K7QCQvBdIT5B+j841AGdvaVCP7PYQesfDQSn9jgHp8y4dloJb/Z6AomD+y91fA7G/FQS6jFIcDwC12wDPbCp6PStSWn/sNmlwEADs/BzY8q7pei4+gG8EULMBUDNSmhaoZqT0nxR7/Q6TTXG6E7IbHk5KTO0dgVExIfhyy2ksPZCCTfFXsCXhCh6LroMJD9Qr1QjVslh2MAW/7U2GTAZ8OayF2UMdALg4KvDDqGjMXJeAn3YlYdamUzh/PRczB1dwxGxl5ewFNOglPQoZ9EBWmnTNXkaKFFwyUqTXt/fWabOlaWCyIc2vV+jMZuDYkpI/V+UBuNaUHm41pVu7xYwvev/URin81WlbFBB0Gqkn0dyniK+fBa6dBrIuF81hmB4vhRy95i4ryIDcm0Uvla5A51dM5zwEpJ4l77qAJlO6p7FOfY8ChLSuXm+6DSGkqXPupM0tfUAqlJ9X9NxgAC4dkgbTONw2UOjEamDfnLJtN7g98NRt4fWXB4H8XGBSbNHE3eoM4OrJojYKZymAKZ0AhZP0+73zp09908+J6CcFale/omUyuTQQSJNddNxyr0v/SUnebbq+ozvgWx8I7VAUyAHpGDPwkZWwx46qlDPp2fh0w0lsOCH1dCkdZHi0IODV8qr4RLqHLtzE8B/3Qqsz4KUeDfBij/r3X6mCFu69gOlrTkBvEGgb5o0fRkXDy6XyTPdic3odcDUBUGcCIe2L/oGM/1MaxKHOlEKNOgPIuSqdOstJlwZs3KnRQ8CQX6XnBgMwo2DC5qlnpOAHAGunSnP8KZyl0b4qN+m5suChcCr+vGYk0PrpgnrzgVXPSeFt5IqiEcNrJgKHf737Pjq6SfMDBjQF/JtIP/0aFq1bFjotYMiXgrMwmD4Klymdi3o+DQbgZpL0vEZY0WnGrDQpKBYyCScy06BS+FzpWnTq2GCQgk/uDSCib1G4O/QLcGq9tDzvhvRTpy5ea+EDAEI6AE+uK/q8+f2kAP7Qt4BfpLTs2mnpPwXugdJAHSdP84YpIaQ6NVnS7/baKeBqohQmr52Sgnth8AvvBjyxumjd2c2k3/HQhYBPwQCsvJsFf66qQK9ydaTTSr9vlXulCOU8FVsCBjv7cDj5Jr7YdAo7T18DIAW8Ia3q4IVuZQ94uVod1sWlYfnBFOxLkm4J1qOhP+aOioZcbp0v9LbEdExYFItsjQ7hvq6YN6a1RXoKqw0hbgt66VLQy74KeAUDEX2kNvlqYH5f6VTk2G1Fc/yteh44uqhsn3fnP+Qf1pJ6GiccAnzrSct2fwPELZPuDeweCHgESqfw/JuYBioyJYQU8Cr7IBudFrhxTgp6KjfptDQg/Tn8KFh6/lpy0TRA6/4HHPgJ8AoBakZIfxY8axcEcJ30HwSDXnpu0ElhPaAZ0PTRos/cN1e6/KBB7/L9J4Ck/1ikJ0i95+Hdir6vZ7YAvw2Wjvm4nUXtV42TvttOnoCTl/QzsIXp2QgLYLArAYOdfTlw/gZmbz6F/85Ic6spHWQY2roOXuhaD0ElBDwhBA5duIllB1Ow9lgqcrTS/7RlMinUzRrSHB5O1p1n7mRaJp5ecBCXbuWhhosSfzzfHnVrcuJfq9NppNNu2mwp9GmzpVOMOrV0+i+/4KdOLS3Pz5NGALccVbSN2N+k08b1unM+v+rOYABuXZBCX+Fk4ACweDiQuO7e691N0yHAIz9Kz/PzgA8KphB6JamoB3b7p0DS9tsGI9WWwqNfo6Je6eooP0/qYU2PB66cKApzWalFbfp9BrR5Vnp+fKV0J56QjsCTa4vafFJXmrz9di1GSrdstCAGuxIw2Nmn/UlSwNt9Vgp4jg5yKeB1q4tAz6KAl5ahxorDF7Hi0EWcu5ZjXB7q44JHo2tjcMvaJQZCS0vPUuPpBQcRdykD0SE1sPy5GKv1GhKRFQkh9SZfS5QCx7XT0q0F5Yqih4PC9HVgC6DZY9L6uTeAf16RtvHEn0WnC0sKjK5+gH8jwK+xdOrfv5F0GYE93g/61AZpkE16vPS4ca7o1P6dPIOlYxE1Cmj4oLSs8NS7Tl10j21AGlCUe0PqiS18BMcUzdtpIQx2JWCws297z13H7M2nsPecdErV0UGOYW3qIDqkBlYevoSdp6/CUPAn3sXRAf2bBuKxVnXQOrRGpRmReulWHnp9vh05Wj3eHdgYo9uH2rokIqoqLh+Rrvm7lVwwMOkicOMscCMJd51ySCYH2j4P9PlQep13U5qLUuksneItdPZfKdAU3qZQCGldZcG1qI5uBT8Ln7tI16Ca8+9VvU7qQZfJinrCc28AR36XLrvoOaOo7U89gYv7Tdd39pYCrV+jgoBbEGwLR1xXYgx2JWCwqx72nL2OLzafwv6Ca+Zu1ybUG4+2qo3+TQPNNjeduS3ccx5v/XkCro4O2PBSZ9SuUcXuUEFElYs2R7r+78oJ4Eo8cOW49DzvBtD9HaDTFKnd5SPA3C6AexDwckLR+oV3lSmLNmOBfp9Kz7PSgF8GSGHv9mvWNr4JpByQrqGUOxRMeyOTRmVrs6XBKoWXRBSO+I4eAwz4smi7syKkkPn65aLex11fANfOFAS4hlIvpZtfpRgIUR6c7oSqvZi6PmgX3g57zl3Ht1vPIC1Djb5NAvFodO0qMShhRNsQrDl6GQfO38Qbq45jwZOtK02PIhFVQY6uQK1o6VFIiILTv7ddT6xyl6aXcfUxXT8oqiA0FY6IlkmnNvPzioKXNqfgOtTcos8spNNIPYnKO/6Tmn4SSNlbtn3R5hY9d/MHmj8uXeeqzy8Kdh1fKts27Qh77IgqqbNXs9H3y53Q6gz4YmhzPBzFP69EVAUY9AXhTiaNEAakAHjpkPQ8tGNR25T9Uq+b0BeMAtYDEFIAVLkVnNYtOM2rcpeeK6rfdFDssSOyA3VruuHF7vXx6YZEvPtXPDrVrwlfN5XVPj9fb4DSgVNwEFEZyR2kEHY7pbNpoCtUp411aqpG+Lc2USU2tnM4GgZ64FZuPt79K97in2cwCGyOv4JH5+xG5FvrsexgisU/k4iIzIfBjqgSUzrI8ckjzSCXAX8dvYzN8Vcs8jlanQHLD6ag9+wdeObXgzh44Sb0BoE3VsXh4PniA1CIiKhyYrAjquSa1vbEs52l+2G+ufo4MtX5Ztt2tkaHn3aeQ5dPt+J/fxzD6fRsuKsUeK5LOHo39ke+XmDcb4eRmpF3/40REZHN8Ro7oirgpR4NsOF4Gs5fz8VH/5zEhw83rdD2rmZpsGB3EhbuuYBMtQ4A4OeuwlMdw/B422B4OCmRo9HhkTm7cTItC88tPIRlz8XASVnJb+tERFTNsceOqApwUjpg5uBmAIBF+5Kx99z1cm3n/LUcvL4qDh0+/hffbj2LTLV0b9qPBjfFzle7YVyXusZbqbmqFPjxiVbwclHi2MUMvL4yDtVsED0RUZXDYEdURcTU9cHwNtLNxF9bcQzqfH2p1427mIHxvx/GA7O2YdG+ZGh1BrSo44XvR0Zj85QuGNYmGCpF8d64Ot4u+PbxlnCQy7Ay9hJ+3pVU4f2wdTgUQuD4pQycuJyBjNx8m9dDRGROPBVLVIVM6xeJf09ewfnruZi9+TRe6xt5z7ZCCPx35jq+334Wu84U3bS6W0RNjOtSF23CvEs16XGHer54o19DzPg7Hh+uS0BkgAc61vctc+3qfD0+Xn8Syw9exBMxIXi5VwQcrHwf3Cx1Pl5edhQbbxuE4qZSoJaXM2rVcEaQlxNqebmgVg1n1PJyRu0azqjppuL9eomoyuAExURVzKb4K3j214NwkMvw5/gOaFLL0+R9vUHgn+Op+GH7OcRdygAAOMhlGNAsEM91qYuGgWW/L6IQAlOXH8OKwxfh5aLEmvEdEexT+tucHU25hSnLjuDs1Rzjsk71ffHVsCjUcLXOZKOnr2Thud8O4dzVHCgdZPBwUuJ6jva+6zkq5HioeRBe7Rtp1XkEiYgK8V6xJWCwI3swYdFh/H0sFY0CPfDnhA5QOsihztdjxeGL+HHHOZy/Lt1yx0kpx7DWwXi6YxjqeFfsfrPqfD2Gzt2Loym3EOHvjpUvtL/vvXbz9QZ8/e8ZfLv1DPQGAT93FR5vG4wftp9DXr4etWs444dR0Wgc5Fnidirqn7hUTF1+FDlaPQI9nTBnZDRa1PFCnlaPS7fycPlWHi7dysOlm6Y/0zLV0BukvyI9nBT4X+8IPN42xOo9jURUvTHYlYDBjuzBtWwNeny+Hbdy8zGhWz24qBwwb9d5XMvWAAC8XJR4IiYUo2NC4GPGXqa0DDUGfLMLV7M06NskAN8+3vKepylPX8nClGVHjb2GA5oH4b2HGsPLxREJqZl4buEhJN/IhZNSjo8GN8OgqFpmq7OQTm/AZxtP4fvtZwEAMeE++PrxqFL3vOn0BsSm3ML0NSdw4nImAKBpLU+8N6gJWtTxMnu9RER3w2BXAgY7shcrD1/ElGVHTZYFeTrhmU7hGNq6zn1708rr0IWbGD53L7R6A6b0bIBJ3eubvG8wCMz7LwmfbEiEVmeAp7MS7w1qgoHNg0za3crV4sUlR7D91FUAwFMdwjCtX6TZbmN2I0eLiYsP478z0gjisZ3D8UrvCCjKsX29QeD3fRfw6YZEZKl1kMmAYa2D8UrvCKudSiai6qss2cXmo2K/++47hIWFwcnJCdHR0di5c+c9227btg0ymazY4+TJk1asmKhyeDiqFrpH+gEAGvi7YdZjzbH9lW54qmOYxUIdAESH1MB7gxoDAD7fdAqbbhuIkHIjF4//tBfvr02AVmdA14ia2PhS52KhDgC8XBwxb0xrTOhWDwAw778kjPxpn7HXsSLiLmZgwNe78N+Z63BxdMA3j0fh9X4NyxXqAOkaxSdiQvHvy13xSMvaEAJYvD8ZD8zahiX7k2EwVKv/HxNRJWbTHrulS5di1KhR+O6779ChQwf88MMP+OmnnxAfH4/g4OBi7bdt24Zu3bohMTERHh5FF4DXrFkTDg6lmziVPXZkT7Q6A85ezUaEv7vVR26+/edx/LrnAtxUCqx6oT1iU25hxl/xyNbo4OLogDf6N8TjbYJLNfJ2/fE0TF1+FNkanck1cOWx7GAK3lx9HFqdAWG+rvhhVDQa+Lvff8Uy2J90A2//eRwn07IAAC3qeOH9QU2KDWQhIjKHKnMqtm3btmjZsiXmzJljXNawYUMMGjQIM2fOLNa+MNjdvHkTXl5e5fpMBjsi88jXGzDyp33Yl3QDzkoH5BXMq9cqpAZmDWmOEB/XMm3vTHoWxi6URq06Osjx3qDGGNq6+H/w7kWj02PGX/H4fV8yAKBHQ398PrS5ccJlc8vXG/DL7vOYvfk0sjU6yGXAyHbSNC6ezpb5TCKqnsqSXWw2j51Wq8WhQ4fw2muvmSzv1asXdu/eXeK6UVFRUKvVaNSoEd58801069bNkqUS0V0oHeT4bkRLDPzmP1y6lQdHBzmm9GqAZzuFl2vUaD0/d/w5vgOmLDuKTfFX8OqKOBxJyUCPhn7Q6gzQ6AzST730s/Ch0emh1Rmw//wNHLuYAZkMmNKjAcZ3q2fRXkylgxzPdArHgOZB+GBtAtYcvYxf91zAf2euYeHTbRHk5WyxzyYiuhebBbtr165Br9fD39/fZLm/vz/S0tLuuk5gYCDmzp2L6OhoaDQaLFy4EN27d8e2bdvQuXPnu66j0Wig0RRds5OVlWW+nSCq5nzcVFj4dBss3p+MwS1rl2uOvNu5Oynxw8hofLv1DD7ffAqL9ydj8f7kUq/v4aTAl8Oj0C3Cr0J1lIW/hxO+Gh6FYa3r4OXlR3H2ag4e+34PFj7dBuE13axWBxERUAnuPHHn9TdCiHtekxMREYGIiAjj65iYGKSkpOCzzz67Z7CbOXMm3n33XfMVTEQmwmu64Y3+jcy2Pblchond66NJbU98t/UMtDoDHBVyOCrkUCkc4Oggv+110XM3RwUGRdWq8Hx95dW+ni/+eL49Rv20D+eu5WDID3vwy1NtLD5HHxHR7WwW7Hx9feHg4FCsdy49Pb1YL15J2rVrh99+++2e70+bNg1Tpkwxvr506RIaNTLfP0JEZBndIvys2vNmDrW8nLFsXAxGz9uPE5czMeyHvZj3ZGu0DvW2dWlEVE3YbLoTR0dHREdHY9OmTSbLN23ahPbt25d6O7GxsQgMDLzn+yqVCh4eHsaHu7t5R8cREd3O102FxWPboU2oN7I0Ooz6eR+2nky3dVlEVE3YdB67KVOm4KeffsK8efOQkJCAl156CcnJyRg3bhwAqbftiSeeMLafPXs2Vq9ejdOnT+PEiROYNm0aVqxYgQkTJthqF4iIivFwUuLXp9vggUg/qPMNePbXg1hz9LKtyyKiasCm19gNHToU169fx4wZM5CamoomTZpg3bp1CAkJAQCkpqYiObnowmmtVoupU6fi0qVLcHZ2RuPGjbF27Vr069fPVrtARHRXTkoH/DAqGlOXH8WfRy7jxSWxyMzLx8h2IbYujYjsGG8pRkRkQQaDwDtrTmDh3gsAgP/1jsALXeuWauJmQLpfbdK1HOgMAm4qBVwcHeCqUkClkJd6G0RUtVWJeeyIiKoDuVyGGQ81hpeLEl//ewafbkhEZl4+XusbWSyY6fQGnE7PRtylDMRdzEDcpQwkpGZCozMU265CLoOrSgE3lQKuKinsuTpKr2Pq+mB4m2A4Kmx+10gisjIGOyIiC5PJZMY7Ury/NgE/7DiHW7n5GN0+FMcvSQGupBDn6ugAZ0cHZGt0UOdL7+sMAhl5+cjIyy/Wfv2JNPy8KwlTe0fgwaaBVr/dHBHZDk/FEhFZ0bIDKXht5TEY7vE3r7tKgca1PNC0liea1PJE01qeCPVxNYYznd6A3Hw9cjQ65Gh0yNbokavRIVujQ45Wh7QMDeb/l4T0LGli9ma1PfFa30i0r+trrV0kIjPjqVgiokpqSOs68HBW4KWlR6GQy0xCXLPaXgjxdimxh03hIIeHg7zEe+CObh+Cn3cm4Ycd53DsYgYe/3EfukbUxGt9IxEZULG7gxBR5cYeOyIiG9Do9FDK5RY9TXotW4Ovt5zG7/uSoTMIyGTAIy1rY0rPBnZzL1u9QSBfbyh4COj0BmgLnvu4OZYYgKsqdb4eWWodarqrbF0KWUlZsguDHRGRnTt/LQefbkjE2rhUAIBKIceTHcLwfNe68HQuHnyEEMjVSuEhS52PzIKf9f3dUcsGgTBPq8ffxy5jyYEUnL2aDZ1eQKs3QKc33POUNgA4KuR4NLo2xnYKR6ivq/UKtoD0TDW2nEzHloQr2HXmGvL1AjMfboohrevYujSyAga7EjDYEVF1FZt8EzP/OYn9STcAAF4uSrQO9ZbCW54OWZr8gjCng/4uiUkhl2FI6zp4sXt9+Hs4WbzeM+lZ+H1fMlYcuohMta5U68hlgNJBDge5DLlavXFZ3yaBeK5LOJrV9rJgxeYjhEB8aia2JEhh7ujFjLu2e++hxhgVE2rd4sjqGOxKwGBHRNWZEAJbEtLx8fqTOJ2eXWJbB7kM7k4KuDsp4Oggx9mrOQCkHr8x7UPxfNe68HJxNGt9Gp0eG05cwe97L2BfQQAFgDrezni8TQgeiPSDSiGHUiGHUi6D0kF6rih47lBwalsIgX1JN/DD9rPYmnjVuJ32dX3wXJe66Fzft9LNA6jO12PvuevYnHAF/yak43KG2uT95nW80CPSD90b+mPF4Yv4eVcSAODN/g3xTKdwW5RsUxm5+Th+OQNtw7yhcLDvqX0Y7ErAYEdEJI2u3RR/BTdytXB3UsLdSQEPJyU8nBRwd1LCw1kBZ6WDSfjZn3QDn6w/iYMXbgIA3J0UeK5zOJ7sEAZXVcXG4iVfz8Wi/clYfjAF13O0AKSeth4N/TGiXQg61fMt9/WIJ9MyMXf7Oaw5ehm6gp7IRoEeeK5LOPo3DbR5KFDn6/HJ+kQsOZBs7GUEACelHB3r1UTPRn7oFukHP/eiXlIhBD7bmIhvt54FALzcswEmdq9v9dqtTaszYGtiOlYdvoR/T6ZDqzegf7NAfDM8qtIFdXNisCsBgx0RUfkJIbA1MR2frE/EybQsAICvmyMmdKuH4W2DoVI4lGo7Wp0B565lI/5yJv48chk7Tl9F4b9G/h4qDGsdjGFt6iDQ03zX9F26lYefdyaZBKjaNZzxbKdwDGlVB86OpavdnE5czsDkJUeMvaf+Hip0b+iPHg390L6uL5yUJdf09ZbTmLXpFABgfLe6mNorwu4CjhACh5NvYuXhS1gbl4pbucXnbpzSswEm2XGwZbArAYMdEVHFGQwCfx27jM83ncKF67kApJD0Uo8GGBRVy+SU6OUMNRLTMpGQmoXENOlx9mq2sfesUOcGNTGibTC6R/pZtBftVq4Wv+65gAW7z+NGQe9gTXcVZj3WHJ0b1LTY597OYBD4adc5fLohEfl6gZruKnz8SFN0i/ArczD7ccc5fLAuAQDwdMcwvNm/oV2Eu/PXcrAq9hJWH7lk/DMGSOH3oRa18HBULRy7eAuvrogDAMwZ0RJ9mwbaqlyLYrArAYMdEZH55OsNWHogBV9tOW2cFLmBvxtahXrjVFoWEq9kIeseAx/cVQpEBLijdZg3hrWugxAf645czdPq8cfhi5i74yxSbuQBAJ7rHI6Xe0VY9HZsqRl5eHnZUew+ex0A0KuRPz56pBm8Xct/veKve87j7T9PAABGtgvGjIFNqtwdR/QGgaRr2dhz9jpWxl5CbPIt43sujg7o0zgAD7eshfZ1fY3/cQCAGX/FY95/SXBWOmD5uBg0qeVpg+oti8GuBAx2RETml6fV45c95zFn29litzlTyGWoW9MNEQHuiAx0R2SAOyICPBDk6VQpepbU+Xp8sDYBC/deACDdrePLYVEIs8AUKWuPpeL1VXHIyMuHs9IB7wxohKGt65jlOCw7kIJXVx6DEMCj0bXx8SPNTAJQZZKvN+D0lWwcv5yBE5cycPxyJuIvZyIvv+gaQ7kM6Fi/JgZH1UKvxv5wcbz7dZw6vQFP/XIQO05dRZCnE/6c0NHu5vhjsCsBgx0RkeVk5OVj8f5k3MrNR2RBkAv3dbNoD5i5bDiRhldXHMOt3Hy4OjrgvUFNMLilef6dyNboMH3NCfxx6CIAoHltT8y2QHj888glTFl2FHqDwIDmQfh8SHMobTw4xGAQOHE5E3GXMoxBLiEtC9q73BfZWemAxkEe6N04AA+1CIJfKafVycjLx8Pf/YdzV3PQMtgLi8e2K/X1nlUBg10JGOyIiOheUjPyMHnJEeNUK4NaBOG9QU3gXoE7WBy6cBMvLT2C5Bu5kMuAF7rWw4s96lsscP0Tl4pJS2KRrxfo3dgfXw2PslnI2XHqKmb+cxIJqZnF3iu8L3KTIOmWek1qeSDM163cvYxJ13Lw0De7kKnWYXDLWpj1WPNy9YSmZ6rx97FU9Gjoj2Afl3LVYm4MdiVgsCMiopLoDQLfbT2D2VtOQ28QCPZ2wVfDo9CijleZtqPTG/D1v2fwzdYz0BsEank544uhLdAmzNsyhd/m35NXMO63w9DqDOhYzxcPR9VCWE1XhPm4okYFruUrreOXMvDRPyex68w1AICrowNahtSQAlyQFOLq1Cj5vsjlsfP0VYyZfwB6g8Dr/SIxtnPdUq+r1RmwYHcSvtx8GjlaPZyVDni9f0OMbBts80sGGOxKwGBHRESlcejCDUxafASXbuVBIZfh5V4ReK5z+F3DiDpfj1NXsnAyNQvxqZk4WTAKuPB6w4ejauHdhxpb9d61u05fwzO/HoA63/SUp6ezEmG+rgjzdUWoj6sx8IX6ulSoZxIAUm7k4rONifjzyGUAgKODHKNiQjChWz2rBEoAWPBfEqb/FQ+ZDJg3ujW6Rfrdd50dp65i+l8ncK5gEm5vV0fjiOlO9X3xyaPNzDr1Tlkx2JWAwY6IiEorIy8fr6+Kw9pj0n12O9bzxev9GiI1Iw8JqZlISMvCydRMJF3Luet9az2dlZjxUGM81KKWlSuXHL+UgUX7k5F0NQfnr+cg9Y67WdzJ30OFVqHeaBfug5hwb9St6Vaq3qqbOVp8s/UMFu65AK1eCpIPtQjC1F4RqONt3dOZQgi8vuo4Fu9PhptKgVUvtEd9f/e7tk25kYv318Zjw4krAKQ5GV/pE4nBUbWwcO8FfPTPSWh0Brg7KfDuwMZ4OKqWTXrvGOxKwGBHRERlIYTA8oMX8c6aEyajNu/k7eqIhoHuaBjggchAD0QGuKO+v1uluog/T6vH+es5OH8tB+euST/PX89B0rUcXMvWFmvv6+aItuE+aBcmhb16fqZBT52vx7z/kjBn21njtDYd6/nitb6RNp12RKszYNTP+7Av6QaCvV3w5/gOJj2G6nw9vt9+FnO2nYVGZ4CDXIbRMaF4sUd9eDoX9VqevZqNl5cdxZGUWwCA3o398cHDTeHrZt1Rtwx2JWCwIyKi8jiTno2py4/ixOUM1K3phoYF4S0y0AMNA91R001l82uxKiJTnY+Ey5nYl3QDe89dx6ELN6G5Y+Sqr5sj2ob5oF24N+RyGb7ecgZpmVIvYMNAD0zrG2m1SZ7v50aOFg99uwspN/IQE+6DX59uA4Vchg0nruD9tfG4eFOauzAm3AfTBzZGRMDde/V0egN+2HEOszefQr5ewMfVER883BR9mgRYbV8Y7ErAYEdERBVhMIgqN/lveWh0ehxNycDec9exL+k6Dp4vHvQAoJaXM17u1QCDWtSqdMclMS0Lg7/7DzlaPR6OqoVr2RrsPC0N6Aj0dMIb/Ruif9PAUgXy+MuZmLLsiPFWeg9H1cL0gY1NevgshcGuBAx2REREZafR6XHsYgb2nr2OvUnXcSVTg6Gt6mBUTMh972lrS5vjr+DZhQeN9yJ2dJBjbOdwvNCt7j0nPb4XjU6PLzefxvfbz8IggAAPJ3zyaDOL91Iy2JWAwY6IiKh6+WnnOXy4LgHdIvzw1oONEFrBiaEPJ9/Ey8uOIumaNIp2ZLtgvPdQE4udii9LdilbVCUiIiKqYp7pFI6R7czXs9gyuAbWTeqEj9efxILd5+Egk1Wa6ysZ7IiIiMjumft0sbOjA6YPbIw+TQLQvLaXWbddEQx2REREROXULtzH1iWYqPx3ZSYiIiKiUmGwIyIiIrITDHZEREREdoLBjoiIiMhOMNgRERER2QkGOyIiIiI7wWBHREREZCcY7IiIiIjsBIMdERERkZ1gsCMiIiKyEwx2RERERHaCwY6IiIjITjDYEREREdkJha0LsDaDwQAASE1NtXElRERERPdXmFkKM0xJql2wu3LlCgCgTZs2Nq6EiIiIqPSuXLmC4ODgEtvIhBDCSvVUCjqdDrGxsfD394dcbrkz0VlZWWjUqBHi4+Ph7u5usc+pjKrzvgPVe/+r874D1Xv/q/O+A9V7/6vzvgPW2X+DwYArV64gKioKCkXJfXLVLthZS2ZmJjw9PZGRkQEPDw9bl2NV1Xnfgeq9/9V534Hqvf/Ved+B6r3/1Xnfgcq3/xw8QURERGQnGOyIiIiI7ASDnYWoVCq88847UKlUti7F6qrzvgPVe/+r874D1Xv/q/O+A9V7/6vzvgOVb/95jR0RERGRnWCPHREREZGdYLAjIiIishMMdkRERER2gsGulL777juEhYXByckJ0dHR2LlzZ4ntt2/fjujoaDg5OSE8PBzff/99sTYrVqxAo0aNoFKp0KhRI6xatcpS5VdYWfZ/5cqV6NmzJ2rWrAkPDw/ExMRgw4YNJm0WLFgAmUxW7KFWqy29K2VWln3ftm3bXffr5MmTJu3s9Xc/ZsyYu+5/48aNjW2qyu9+x44dGDBgAIKCgiCTybB69er7rmMv3/uy7ru9fefLuv/29L0v677b03d+5syZaN26Ndzd3eHn54dBgwYhMTHxvutVtu89g10pLF26FJMnT8Ybb7yB2NhYdOrUCX379kVycvJd2yclJaFfv37o1KkTYmNj8frrr2PSpElYsWKFsc2ePXswdOhQjBo1CkePHsWoUaMwZMgQ7Nu3z1q7VWpl3f8dO3agZ8+eWLduHQ4dOoRu3bphwIABiI2NNWnn4eGB1NRUk4eTk5M1dqnUyrrvhRITE032q379+sb37Pl3/+WXX5rsd0pKCry9vfHYY4+ZtKsKv/ucnBw0b94c33zzTana29P3vqz7bk/feaDs+1/IHr73Zd13e/rOb9++HePHj8fevXuxadMm6HQ69OrVCzk5Ofdcp1J+7wXdV5s2bcS4ceNMlkVGRorXXnvtru1feeUVERkZabLsueeeE+3atTO+HjJkiOjTp49Jm969e4thw4aZqWrzKev+302jRo3Eu+++a3w9f/584enpaa4SLaas+75161YBQNy8efOe26xOv/tVq1YJmUwmzp8/b1xWVX73twMgVq1aVWIbe/veFyrNvt9NVf3O36k0+29v3/tC5fnd28t3Xggh0tPTBQCxffv2e7apjN979tjdh1arxaFDh9CrVy+T5b169cLu3bvvus6ePXuKte/duzcOHjyI/Pz8Etvca5u2Up79v5PBYEBWVha8vb1NlmdnZyMkJAS1a9fGgw8+WOx/97ZWkX2PiopCYGAgunfvjq1bt5q8V51+9z///DN69OiBkJAQk+WV/XdfHvb0va+oqvqdryh7+N5XlD195zMyMgCg2J/j21XG7z2D3X1cu3YNer0e/v7+Jsv9/f2RlpZ213XS0tLu2l6n0+HatWsltrnXNm2lPPt/p1mzZiEnJwdDhgwxLouMjMSCBQuwZs0aLF68GE5OTujQoQNOnz5t1vorojz7HhgYiLlz52LFihVYuXIlIiIi0L17d+zYscPYprr87lNTU/HPP//gmWeeMVleFX735WFP3/uKqqrf+fKyp+99RdjTd14IgSlTpqBjx45o0qTJPdtVxu+9wiJbtUMymczktRCi2LL7tb9zeVm3aUvlrXXx4sWYPn06/vzzT/j5+RmXt2vXDu3atTO+7tChA1q2bImvv/4aX331lfkKN4Oy7HtERAQiIiKMr2NiYpCSkoLPPvsMnTt3Ltc2ba28tS5YsABeXl4YNGiQyfKq9LsvK3v73peHPXzny8oev/flYU/f+QkTJuDYsWPYtWvXfdtWtu89e+zuw9fXFw4ODsWSdXp6erEEXiggIOCu7RUKBXx8fEpsc69t2kp59r/Q0qVL8fTTT2PZsmXo0aNHiW3lcjlat25dqf4HV5F9v127du1M9qs6/O6FEJg3bx5GjRoFR0fHEttWxt99edjT9768qvp33pyq6ve+vOzpOz9x4kSsWbMGW7duRe3atUtsWxm/9wx29+Ho6Ijo6Ghs2rTJZPmmTZvQvn37u64TExNTrP3GjRvRqlUrKJXKEtvca5u2Up79B6T/tY8ZMwaLFi1C//797/s5QggcOXIEgYGBFa7ZXMq773eKjY012S97/90D0uiyM2fO4Omnn77v51TG33152NP3vjzs4TtvTlX1e19e9vCdF0JgwoQJWLlyJf7991+EhYXdd51K+b23yJAMO7NkyRKhVCrFzz//LOLj48XkyZOFq6urcdTPa6+9JkaNGmVsf+7cOeHi4iJeeuklER8fL37++WehVCrFH3/8YWzz33//CQcHB/HRRx+JhIQE8dFHHwmFQiH27t1r9f27n7Lu/6JFi4RCoRDffvutSE1NNT5u3bplbDN9+nSxfv16cfbsWREbGyuefPJJoVAoxL59+6y+fyUp675/8cUXYtWqVeLUqVPi+PHj4rXXXhMAxIoVK4xt7Pl3X2jkyJGibdu2d91mVfndZ2VlidjYWBEbGysAiM8//1zExsaKCxcuCCHs+3tf1n23p++8EGXff3v63pd13wvZw3f++eefF56enmLbtm0mf45zc3ONbarC957BrpS+/fZbERISIhwdHUXLli1Nhj+PHj1adOnSxaT9tm3bRFRUlHB0dBShoaFizpw5xba5fPlyERERIZRKpYiMjDT5S6CyKcv+d+nSRQAo9hg9erSxzeTJk0VwcLBwdHQUNWvWFL169RK7d++24h6VXln2/eOPPxZ169YVTk5OokaNGqJjx45i7dq1xbZpr797IYS4deuWcHZ2FnPnzr3r9qrK775wCot7/Tm25+99Wffd3r7zZd1/e/rel+fPvb185++23wDE/PnzjW2qwvdeVrAzRERERFTF8Ro7IiIiIjvBYEdERERkJxjsiIiIiOwEgx0RERGRnWCwIyIiIrITDHZEREREdoLBjoiIiMhOMNgRERER2QkGOyIiK5PJZFi9erWtyyAiO8RgR0TVypgxYyCTyYo9+vTpY+vSiIgqTGHrAoiIrK1Pnz6YP3++yTKVSmWjaoiIzIc9dkRU7ahUKgQEBJg8atSoAUA6TTpnzhz07dsXzs7OCAsLw/Lly03Wj4uLwwMPPABnZ2f4+Phg7NixyM7ONmkzb948NG7cGCqVCoGBgZgwYYLJ+9euXcPDDz8MFxcX1K9fH2vWrDG+d/PmTYwYMQI1a9aEs7Mz6tevXyyIEhHdDYMdEdEd3nrrLTzyyCM4evQoRo4cieHDhyMhIQEAkJubiz59+qBGjRo4cOAAli9fjs2bN5sEtzlz5mD8+PEYO3Ys4uLisGbNGtSrV8/kM959910MGTIEx44dQ79+/TBixAjcuHHD+Pnx8fH4559/kJCQgDlz5sDX19d6B4CIqi5BRFSNjB49Wjg4OAhXV1eTx4wZM4QQQgAQ48aNM1mnbdu24vnnnxdCCDF37lxRo0YNkZ2dbXx/7dq1Qi6Xi7S0NCGEEEFBQeKNN964Zw0AxJtvvml8nZ2dLWQymfjnn3+EEEIMGDBAPPnkk+bZYSKqVniNHRFVO926dcOcOXNMlnl7exufx8TEmLwXExODI0eOAAASEhLQvHlzuLq6Gt/v0KEDDAYDEhMTIZPJcPnyZXTv3r3EGpo1a2Z87urqCnd3d6SnpwMAnn/+eTzyyCM4fPgwevXqhUGDBqF9+/bl2lciql4Y7Iio2nF1dS12avR+ZDIZAEAIYXx+tzbOzs6l2p5SqSy2rsFgAAD07dsXFy5cwNq1a7F582Z0794d48ePx2effVammomo+uE1dkREd9i7d2+x15GRkQCARo0a4ciRI8jJyTG+/99//0Eul6NBgwZwd3dHaGgotmzZUqEaatasiTFjxuC3337D7NmzMXfu3Aptj4iqB/bYEVG1o9FokJaWZrJMoVAYBygsX74crVq1QseOHfH7779j//79+PnnnwEAI0aMwDvvvIPRo0dj+vTpuHr1KiZOnIhRo0bB398fADB9+nSMGzcOfn5+6Nu3L7KysvDff/9h4sSJparv7bffRnR0NBo3bgyNRoO///4bDRs2NOMRICJ7xWBHRNXO+vXrERgYaLIsIiICJ0+eBCCNWF2yZAleeOEFBAQE4Pfff0ejRo0AAC4uLtiwYQNefPFFtG7dGi4uLnjkkUfw+eefG7c1evRoqNVqfPHFF5g6dSp8fX3x6KOPlro+R0dHTJs2DefPn4ezszM6deqEJUuWmGHPicjeyYQQwtZFEBFVFjKZDKtWrcKgQYNsXQoRUZnxGjsiIiIiO8FgR0RERGQneI0dEdFteHUKEVVl7LEjIiIishMMdkRERER2gsGOiIiIyE4w2BERERHZCQY7IiIiIjvBYEdERERkJxjsiIiIiOwEgx0RERGRnWCwIyIiIrIT/wdrb98Ix4qt0AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.train import plot_losses\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e080de23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from utils.train import generate, text_to_token_ids, token_ids_to_text\n",
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    ")\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
